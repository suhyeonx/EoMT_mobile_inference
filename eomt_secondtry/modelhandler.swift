//
//  modelhandler.swift
//  eomt_secondtry
//
//  Created by ì´ìˆ˜í˜„ on 11/17/25.
//

import CoreML
import UIKit
class ModelHandler {
    private let model: MLModel
    
    init() {
        guard let modelURL = Bundle.main.url(forResource: "EOMT_2", withExtension: "mlmodelc") else {
            fatalError("Model not found")
        }
        
        // 1ï¸âƒ£ Configuration ìƒì„±
        let config = MLModelConfiguration()
        config.computeUnits = .all  // Neural Engine + GPU + CPU ëª¨ë‘ ì‚¬ìš©
        // ë§Œì•½ Neural Engineë§Œ ì‚¬ìš©í•˜ê³  ì‹¶ë‹¤ë©´:
        // config.computeUnits = .cpuAndNeuralEngine
        
        do {
            // 2ï¸âƒ£ configurationì„ ì „ë‹¬í•˜ì—¬ ëª¨ë¸ ë¡œë“œ
            self.model = try MLModel(contentsOf: modelURL, configuration: config)
        } catch {
            fatalError("Failed to load model: \(error)")
        }
    }
    
    func predict(image: UIImage) -> (classLogits: MLMultiArray, maskLogits: MLMultiArray, padInfo: CGRect)?{
        // 1. ì „ì²˜ë¦¬ (Letterbox Resize + Padding)
        let targetSize = CGSize(width: 640, height: 640)
        let (inputImage, padRect) = resizeWithPadding(image: image, targetSize: targetSize)
        
        // 2. CVPixelBufferë¡œ ë³€í™˜
        guard let pixelBuffer = inputImage.toCVPixelBuffer() else {
            return nil
        }
        
        // 3. ëª¨ë¸ ì…ë ¥ ìƒì„±
        // MLModelì˜ prediction(from:)ì„ ì‚¬ìš©í•˜ë ¤ë©´ MLFeatureProviderë¥¼ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤.
        // ì…ë ¥ í‚¤ëŠ” convert.pyì—ì„œ ì§€ì •í•œ "pixel_values"ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
        let inputFeatures: MLFeatureProvider
        do {
            // CVPixelBufferë¥¼ ì…ë ¥í•˜ëŠ” MLFeatureProviderë¥¼ ë§Œë“­ë‹ˆë‹¤.
            let inputDict = ["pixel_values": pixelBuffer] as [String: Any]
            inputFeatures = try MLDictionaryFeatureProvider(dictionary: inputDict)
        } catch {
            print("Error creating input feature provider: \(error)")
            return nil
        }
        
        // 4. ì¶”ë¡  ì‹¤í–‰
        guard let outputFeatures = try? model.prediction(from: inputFeatures) else {
            print("Error: Model prediction failed.")
            return nil
        }
        
        // 5. ê²°ê³¼ ì¶”ì¶œ (Output KeyëŠ” convert.pyì—ì„œ ì§€ì •í•œ ì´ë¦„ ì‚¬ìš©)
        guard let classLogits = outputFeatures.featureValue(for: "class_logits")?.multiArrayValue,
              let maskLogits = outputFeatures.featureValue(for: "mask_logits")?.multiArrayValue else {
            print("Error: Could not retrieve class_logits or mask_logits from model output.")
            return nil
        }
        
        // 6. ê²°ê³¼ íŠœí”Œ ë°˜í™˜ (ì „ì²˜ë¦¬ì—ì„œ ì–»ì€ padRectë¥¼ í•¨ê»˜ ë°˜í™˜)
        return (classLogits, maskLogits, padRect)
    }
}
// -----------------------------------------------------------
    // ğŸ’¡ Helper: resizeWithPadding í•¨ìˆ˜ (Letterbox êµ¬í˜„)
    // -----------------------------------------------------------
    private func resizeWithPadding(image: UIImage, targetSize: CGSize) -> (UIImage, CGRect) {
        let originalSize = image.size
        let targetWidth = targetSize.width
        let targetHeight = targetSize.height
        
        // ë¹„ìœ¨ ê³„ì‚° (Python: min(target_w / orig_w, target_h / orig_h))
        let ratio = min(targetWidth / originalSize.width, targetHeight / originalSize.height)
        
        let newWidth = originalSize.width * ratio
        let newHeight = originalSize.height * ratio
        
        // ê·¸ë¦´ ìœ„ì¹˜ ê³„ì‚° (ì¤‘ì•™ ì •ë ¬)
        let x = (targetWidth - newWidth) / 2
        let y = (targetHeight - newHeight) / 2
        let drawRect = CGRect(x: x, y: y, width: newWidth, height: newHeight)
        
        // ê·¸ë˜í”½ ì»¨í…ìŠ¤íŠ¸ ì‹œì‘ (ê²€ì€ ë°°ê²½)
        let rendererFormat = UIGraphicsImageRendererFormat.default()
        rendererFormat.scale = 1.0 // Core ML ì…ë ¥ì„ ìœ„í•´ ìŠ¤ì¼€ì¼ì„ 1.0ìœ¼ë¡œ ê°•ì œ
        let renderer = UIGraphicsImageRenderer(size: targetSize, format: rendererFormat)
        
        let newImage = renderer.image { context in
            // 1. ê²€ì€ìƒ‰ ì±„ìš°ê¸°
            UIColor.black.setFill()
            context.fill(CGRect(origin: .zero, size: targetSize))
            
            // 2. ì´ë¯¸ì§€ ì¤‘ì•™ì— ê·¸ë¦¬ê¸°
            image.draw(in: drawRect)
        }
        
        // drawRectëŠ” ë‚˜ì¤‘ì— Cropí•  ë•Œ ì‚¬ìš©ë¨ (Pythonì˜ pad_info)
        return (newImage, drawRect)
    }


// -----------------------------------------------------------
// ğŸ’¡ Extension: UIImage -> CVPixelBuffer ë³€í™˜
// -----------------------------------------------------------
extension UIImage {
    func toCVPixelBuffer() -> CVPixelBuffer? {
        // CGImageë¥¼ ì–»ì„ ìˆ˜ ì—†ìœ¼ë©´ ì‹¤íŒ¨
        guard let cgImage = self.cgImage else { return nil }
        
        let width = cgImage.width
        let height = cgImage.height
        
        let attrs = [
            kCVPixelBufferCGImageCompatibilityKey: kCFBooleanTrue,
            kCVPixelBufferCGBitmapContextCompatibilityKey: kCFBooleanTrue
        ] as CFDictionary
        
        var pixelBuffer: CVPixelBuffer?
        let status = CVPixelBufferCreate(
            kCFAllocatorDefault,
            width,
            height,
            kCVPixelFormatType_32BGRA, // Core ML ImageType ì…ë ¥ê³¼ í˜¸í™˜ë˜ëŠ” í¬ë§· (BGRA ë˜ëŠ” ARGB)
            attrs,
            &pixelBuffer
        )
        
        guard status == kCVReturnSuccess, let buffer = pixelBuffer else { return nil }
        
        CVPixelBufferLockBaseAddress(buffer, .init(rawValue: 0))
        let pixelData = CVPixelBufferGetBaseAddress(buffer)
        
        let rgbColorSpace = CGColorSpaceCreateDeviceRGB()
        
        // CGContext ìƒì„±
        guard let context = CGContext(
            data: pixelData,
            width: width,
            height: height,
            bitsPerComponent: 8,
            bytesPerRow: CVPixelBufferGetBytesPerRow(buffer),
            space: rgbColorSpace,
            bitmapInfo: CGImageAlphaInfo.premultipliedFirst.rawValue // 32BGRAì˜ ê²½ìš°
        ) else { return nil }
        
        // ì´ë¯¸ì§€ ê·¸ë¦¬ê¸° (ìƒí•˜ ë°˜ì „ ë°©ì§€ ë° ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ì— ë§ì¶¤)
        context.translateBy(x: 0, y: CGFloat(height))
        context.scaleBy(x: 1.0, y: -1.0)
        
        // Core ML ëª¨ë¸ì€ RGB í¬ë§·ì„ ìš”êµ¬í•˜ë¯€ë¡œ, ì—¬ê¸°ì„œëŠ” ì´ë¯¸ì§€ ìì²´ë¥¼ ê·¸ë¦½ë‹ˆë‹¤.
        context.draw(cgImage, in: CGRect(x: 0, y: 0, width: width, height: height))
        
        CVPixelBufferUnlockBaseAddress(buffer, .init(rawValue: 0))
        
        return buffer
    }
}

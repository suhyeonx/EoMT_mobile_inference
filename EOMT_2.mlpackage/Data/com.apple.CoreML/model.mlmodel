›

pixel_values
"ÄÄR
class_logits*
»Ü†ÄR
mask_logits*
»†††Ä¢˛
!EOMT Panoptic Segmentation (FP32)¢3
#com.github.apple.coremltools.sourcetorch==2.8.0¢-
$com.github.apple.coremltools.version8.3.0¢5
#com.apple.coreml.model.preview.typeimageSegmenter¢:
+com.github.apple.coremltools.source_dialectTorchScript≤íì¢ë
mainòë
0
pixel_values 



Ä
ÄCoreML6Ÿê
CoreML6Ãêclass_logitsmask_logitsx
const"
pixel_values__scaled___y_0
*0
name(
 
"
pixel_values__scaled___y_0*
val




%é<´
mul
x

pixel_values#
y

pixel_values__scaled___y_0:
pixel_values__scaled__ 



Ä
Ä*,
name$

"
pixel_values__scaled__¥
const<
pixel_values__biased___y_0




*0
name(
 
"
pixel_values__biased___y_0*;
val4







Ωã¿%I¿	¯Êøµ
add
x

pixel_values__scaled__#
y

pixel_values__biased___y_0:
pixel_values__biased__ 



Ä
Ä*,
name$

"
pixel_values__biased__∆
const=
 model_embeddings_register_tokens



Ä*6
name.
&
$""
 model_embeddings_register_tokens*F
val?



Ä*"
@model_path/weights/weight.bin@ª
const7
model_embeddings_cls_token



Ä*0
name(
 
"
model_embeddings_cls_token*G
val@



Ä*#
@model_path/weights/weight.binÄ1—
constB
1model_embeddings_patch_embeddings_projection_bias

Ä*G
name?
7
5"3
1model_embeddings_patch_embeddings_projection_bias*;
val4

Ä*#
@model_path/weights/weight.bin¿=˘
constV
3model_embeddings_patch_embeddings_projection_weight

Ä


*I
nameA
9
7"5
3model_embeddings_patch_embeddings_projection_weight*M
valF

Ä


*#
@model_path/weights/weight.binÄJ¢
const*
model_layers_0_norm1_bias

Ä*/
name'

"
model_layers_0_norm1_bias*<
val5

Ä*$
@model_path/weights/weight.bin¿ H¶
const,
model_layers_0_norm1_weight

Ä*1
name)
!
"
model_layers_0_norm1_weight*<
val5

Ä*$
@model_path/weights/weight.binÄ◊H∏
const5
$model_layers_0_attention_q_proj_bias

Ä*:
name2
*
("&
$model_layers_0_attention_q_proj_bias*<
val5

Ä*$
@model_path/weights/weight.bin¿„H 
const>
&model_layers_0_attention_q_proj_weight

Ä
Ä*<
name4
,
*"(
&model_layers_0_attention_q_proj_weight*C
val<

Ä
Ä*$
@model_path/weights/weight.binÄH∏
const5
$model_layers_0_attention_k_proj_bias

Ä*:
name2
*
("&
$model_layers_0_attention_k_proj_bias*<
val5

Ä*$
@model_path/weights/weight.bin¿l 
const>
&model_layers_0_attention_k_proj_weight

Ä
Ä*<
name4
,
*"(
&model_layers_0_attention_k_proj_weight*C
val<

Ä
Ä*$
@model_path/weights/weight.binÄ˝lπ
const5
$model_layers_0_attention_v_proj_bias

Ä*:
name2
*
("&
$model_layers_0_attention_v_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿˝êÀ
const>
&model_layers_0_attention_v_proj_weight

Ä
Ä*<
name4
,
*"(
&model_layers_0_attention_v_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄäëΩ
const7
&model_layers_0_attention_out_proj_bias

Ä*<
name4
,
*"(
&model_layers_0_attention_out_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿äµœ
const@
(model_layers_0_attention_out_proj_weight

Ä
Ä*>
name6
.
,"*
(model_layers_0_attention_out_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄóµ∑
const4
#model_layers_0_layer_scale1_lambda1

Ä*9
name1
)
'"%
#model_layers_0_layer_scale1_lambda1*=
val6

Ä*%
@model_path/weights/weight.bin¿óŸ£
const*
model_layers_0_norm2_bias

Ä*/
name'

"
model_layers_0_norm2_bias*=
val6

Ä*%
@model_path/weights/weight.binÄ§Ÿß
const,
model_layers_0_norm2_weight

Ä*1
name)
!
"
model_layers_0_norm2_weight*=
val6

Ä*%
@model_path/weights/weight.bin¿∞Ÿß
const,
model_layers_0_mlp_fc1_bias

Ä*1
name)
!
"
model_layers_0_mlp_fc1_bias*=
val6

Ä*%
@model_path/weights/weight.binÄΩŸπ
const5
model_layers_0_mlp_fc1_weight

Ä
Ä*3
name+
#
!"
model_layers_0_mlp_fc1_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.bin¿ÌŸß
const,
model_layers_0_mlp_fc2_bias

Ä*1
name)
!
"
model_layers_0_mlp_fc2_bias*=
val6

Ä*%
@model_path/weights/weight.binÄÓÈπ
const5
model_layers_0_mlp_fc2_weight

Ä
Ä*3
name+
#
!"
model_layers_0_mlp_fc2_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.bin¿˙È∑
const4
#model_layers_0_layer_scale2_lambda1

Ä*9
name1
)
'"%
#model_layers_0_layer_scale2_lambda1*=
val6

Ä*%
@model_path/weights/weight.binÄ˚˘£
const*
model_layers_1_norm1_bias

Ä*/
name'

"
model_layers_1_norm1_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿á˙ß
const,
model_layers_1_norm1_weight

Ä*1
name)
!
"
model_layers_1_norm1_weight*=
val6

Ä*%
@model_path/weights/weight.binÄî˙π
const5
$model_layers_1_attention_q_proj_bias

Ä*:
name2
*
("&
$model_layers_1_attention_q_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿†˙À
const>
&model_layers_1_attention_q_proj_weight

Ä
Ä*<
name4
,
*"(
&model_layers_1_attention_q_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄ≠˙π
const5
$model_layers_1_attention_k_proj_bias

Ä*:
name2
*
("&
$model_layers_1_attention_k_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿≠ûÀ
const>
&model_layers_1_attention_k_proj_weight

Ä
Ä*<
name4
,
*"(
&model_layers_1_attention_k_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄ∫ûπ
const5
$model_layers_1_attention_v_proj_bias

Ä*:
name2
*
("&
$model_layers_1_attention_v_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿∫¬À
const>
&model_layers_1_attention_v_proj_weight

Ä
Ä*<
name4
,
*"(
&model_layers_1_attention_v_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄ«¬Ω
const7
&model_layers_1_attention_out_proj_bias

Ä*<
name4
,
*"(
&model_layers_1_attention_out_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿«Êœ
const@
(model_layers_1_attention_out_proj_weight

Ä
Ä*>
name6
.
,"*
(model_layers_1_attention_out_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄ‘Ê∑
const4
#model_layers_1_layer_scale1_lambda1

Ä*9
name1
)
'"%
#model_layers_1_layer_scale1_lambda1*=
val6

Ä*%
@model_path/weights/weight.bin¿‘ä£
const*
model_layers_1_norm2_bias

Ä*/
name'

"
model_layers_1_norm2_bias*=
val6

Ä*%
@model_path/weights/weight.binÄ·äß
const,
model_layers_1_norm2_weight

Ä*1
name)
!
"
model_layers_1_norm2_weight*=
val6

Ä*%
@model_path/weights/weight.bin¿Ìäß
const,
model_layers_1_mlp_fc1_bias

Ä*1
name)
!
"
model_layers_1_mlp_fc1_bias*=
val6

Ä*%
@model_path/weights/weight.binÄ˙äπ
const5
model_layers_1_mlp_fc1_weight

Ä
Ä*3
name+
#
!"
model_layers_1_mlp_fc1_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.bin¿™ãß
const,
model_layers_1_mlp_fc2_bias

Ä*1
name)
!
"
model_layers_1_mlp_fc2_bias*=
val6

Ä*%
@model_path/weights/weight.binÄ´õπ
const5
model_layers_1_mlp_fc2_weight

Ä
Ä*3
name+
#
!"
model_layers_1_mlp_fc2_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.bin¿∑õ∑
const4
#model_layers_1_layer_scale2_lambda1

Ä*9
name1
)
'"%
#model_layers_1_layer_scale2_lambda1*=
val6

Ä*%
@model_path/weights/weight.binÄ∏´£
const*
model_layers_2_norm1_bias

Ä*/
name'

"
model_layers_2_norm1_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿ƒ´ß
const,
model_layers_2_norm1_weight

Ä*1
name)
!
"
model_layers_2_norm1_weight*=
val6

Ä*%
@model_path/weights/weight.binÄ—´π
const5
$model_layers_2_attention_q_proj_bias

Ä*:
name2
*
("&
$model_layers_2_attention_q_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿›´À
const>
&model_layers_2_attention_q_proj_weight

Ä
Ä*<
name4
,
*"(
&model_layers_2_attention_q_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄÍ´π
const5
$model_layers_2_attention_k_proj_bias

Ä*:
name2
*
("&
$model_layers_2_attention_k_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿ÍœÀ
const>
&model_layers_2_attention_k_proj_weight

Ä
Ä*<
name4
,
*"(
&model_layers_2_attention_k_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄ˜œπ
const5
$model_layers_2_attention_v_proj_bias

Ä*:
name2
*
("&
$model_layers_2_attention_v_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿˜ÛÀ
const>
&model_layers_2_attention_v_proj_weight

Ä
Ä*<
name4
,
*"(
&model_layers_2_attention_v_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄÑÙΩ
const7
&model_layers_2_attention_out_proj_bias

Ä*<
name4
,
*"(
&model_layers_2_attention_out_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿Ñòœ
const@
(model_layers_2_attention_out_proj_weight

Ä
Ä*>
name6
.
,"*
(model_layers_2_attention_out_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄëò∑
const4
#model_layers_2_layer_scale1_lambda1

Ä*9
name1
)
'"%
#model_layers_2_layer_scale1_lambda1*=
val6

Ä*%
@model_path/weights/weight.bin¿ëº£
const*
model_layers_2_norm2_bias

Ä*/
name'

"
model_layers_2_norm2_bias*=
val6

Ä*%
@model_path/weights/weight.binÄûºß
const,
model_layers_2_norm2_weight

Ä*1
name)
!
"
model_layers_2_norm2_weight*=
val6

Ä*%
@model_path/weights/weight.bin¿™ºß
const,
model_layers_2_mlp_fc1_bias

Ä*1
name)
!
"
model_layers_2_mlp_fc1_bias*=
val6

Ä*%
@model_path/weights/weight.binÄ∑ºπ
const5
model_layers_2_mlp_fc1_weight

Ä
Ä*3
name+
#
!"
model_layers_2_mlp_fc1_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.bin¿Áºß
const,
model_layers_2_mlp_fc2_bias

Ä*1
name)
!
"
model_layers_2_mlp_fc2_bias*=
val6

Ä*%
@model_path/weights/weight.binÄËÃ	π
const5
model_layers_2_mlp_fc2_weight

Ä
Ä*3
name+
#
!"
model_layers_2_mlp_fc2_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.bin¿ÙÃ	∑
const4
#model_layers_2_layer_scale2_lambda1

Ä*9
name1
)
'"%
#model_layers_2_layer_scale2_lambda1*=
val6

Ä*%
@model_path/weights/weight.binÄı‹
£
const*
model_layers_3_norm1_bias

Ä*/
name'

"
model_layers_3_norm1_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿Å›
ß
const,
model_layers_3_norm1_weight

Ä*1
name)
!
"
model_layers_3_norm1_weight*=
val6

Ä*%
@model_path/weights/weight.binÄé›
π
const5
$model_layers_3_attention_q_proj_bias

Ä*:
name2
*
("&
$model_layers_3_attention_q_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿ö›
À
const>
&model_layers_3_attention_q_proj_weight

Ä
Ä*<
name4
,
*"(
&model_layers_3_attention_q_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄß›
π
const5
$model_layers_3_attention_k_proj_bias

Ä*:
name2
*
("&
$model_layers_3_attention_k_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿ßÅÀ
const>
&model_layers_3_attention_k_proj_weight

Ä
Ä*<
name4
,
*"(
&model_layers_3_attention_k_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄ¥Åπ
const5
$model_layers_3_attention_v_proj_bias

Ä*:
name2
*
("&
$model_layers_3_attention_v_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿¥•À
const>
&model_layers_3_attention_v_proj_weight

Ä
Ä*<
name4
,
*"(
&model_layers_3_attention_v_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄ¡•Ω
const7
&model_layers_3_attention_out_proj_bias

Ä*<
name4
,
*"(
&model_layers_3_attention_out_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿¡…œ
const@
(model_layers_3_attention_out_proj_weight

Ä
Ä*>
name6
.
,"*
(model_layers_3_attention_out_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄŒ…∑
const4
#model_layers_3_layer_scale1_lambda1

Ä*9
name1
)
'"%
#model_layers_3_layer_scale1_lambda1*=
val6

Ä*%
@model_path/weights/weight.bin¿ŒÌ£
const*
model_layers_3_norm2_bias

Ä*/
name'

"
model_layers_3_norm2_bias*=
val6

Ä*%
@model_path/weights/weight.binÄ€Ìß
const,
model_layers_3_norm2_weight

Ä*1
name)
!
"
model_layers_3_norm2_weight*=
val6

Ä*%
@model_path/weights/weight.bin¿ÁÌß
const,
model_layers_3_mlp_fc1_bias

Ä*1
name)
!
"
model_layers_3_mlp_fc1_bias*=
val6

Ä*%
@model_path/weights/weight.binÄÙÌπ
const5
model_layers_3_mlp_fc1_weight

Ä
Ä*3
name+
#
!"
model_layers_3_mlp_fc1_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.bin¿§Óß
const,
model_layers_3_mlp_fc2_bias

Ä*1
name)
!
"
model_layers_3_mlp_fc2_bias*=
val6

Ä*%
@model_path/weights/weight.binÄ•˛π
const5
model_layers_3_mlp_fc2_weight

Ä
Ä*3
name+
#
!"
model_layers_3_mlp_fc2_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.bin¿±˛∑
const4
#model_layers_3_layer_scale2_lambda1

Ä*9
name1
)
'"%
#model_layers_3_layer_scale2_lambda1*=
val6

Ä*%
@model_path/weights/weight.binÄ≤é£
const*
model_layers_4_norm1_bias

Ä*/
name'

"
model_layers_4_norm1_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿æéß
const,
model_layers_4_norm1_weight

Ä*1
name)
!
"
model_layers_4_norm1_weight*=
val6

Ä*%
@model_path/weights/weight.binÄÀéπ
const5
$model_layers_4_attention_q_proj_bias

Ä*:
name2
*
("&
$model_layers_4_attention_q_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿◊éÀ
const>
&model_layers_4_attention_q_proj_weight

Ä
Ä*<
name4
,
*"(
&model_layers_4_attention_q_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄ‰éπ
const5
$model_layers_4_attention_k_proj_bias

Ä*:
name2
*
("&
$model_layers_4_attention_k_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿‰≤À
const>
&model_layers_4_attention_k_proj_weight

Ä
Ä*<
name4
,
*"(
&model_layers_4_attention_k_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄÒ≤π
const5
$model_layers_4_attention_v_proj_bias

Ä*:
name2
*
("&
$model_layers_4_attention_v_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿Ò÷À
const>
&model_layers_4_attention_v_proj_weight

Ä
Ä*<
name4
,
*"(
&model_layers_4_attention_v_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄ˛÷Ω
const7
&model_layers_4_attention_out_proj_bias

Ä*<
name4
,
*"(
&model_layers_4_attention_out_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿˛˙œ
const@
(model_layers_4_attention_out_proj_weight

Ä
Ä*>
name6
.
,"*
(model_layers_4_attention_out_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄã˚∑
const4
#model_layers_4_layer_scale1_lambda1

Ä*9
name1
)
'"%
#model_layers_4_layer_scale1_lambda1*=
val6

Ä*%
@model_path/weights/weight.bin¿ãü£
const*
model_layers_4_norm2_bias

Ä*/
name'

"
model_layers_4_norm2_bias*=
val6

Ä*%
@model_path/weights/weight.binÄòüß
const,
model_layers_4_norm2_weight

Ä*1
name)
!
"
model_layers_4_norm2_weight*=
val6

Ä*%
@model_path/weights/weight.bin¿§üß
const,
model_layers_4_mlp_fc1_bias

Ä*1
name)
!
"
model_layers_4_mlp_fc1_bias*=
val6

Ä*%
@model_path/weights/weight.binÄ±üπ
const5
model_layers_4_mlp_fc1_weight

Ä
Ä*3
name+
#
!"
model_layers_4_mlp_fc1_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.bin¿·üß
const,
model_layers_4_mlp_fc2_bias

Ä*1
name)
!
"
model_layers_4_mlp_fc2_bias*=
val6

Ä*%
@model_path/weights/weight.binÄ‚Øπ
const5
model_layers_4_mlp_fc2_weight

Ä
Ä*3
name+
#
!"
model_layers_4_mlp_fc2_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.bin¿ÓØ∑
const4
#model_layers_4_layer_scale2_lambda1

Ä*9
name1
)
'"%
#model_layers_4_layer_scale2_lambda1*=
val6

Ä*%
@model_path/weights/weight.binÄÔø£
const*
model_layers_5_norm1_bias

Ä*/
name'

"
model_layers_5_norm1_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿˚øß
const,
model_layers_5_norm1_weight

Ä*1
name)
!
"
model_layers_5_norm1_weight*=
val6

Ä*%
@model_path/weights/weight.binÄà¿π
const5
$model_layers_5_attention_q_proj_bias

Ä*:
name2
*
("&
$model_layers_5_attention_q_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿î¿À
const>
&model_layers_5_attention_q_proj_weight

Ä
Ä*<
name4
,
*"(
&model_layers_5_attention_q_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄ°¿π
const5
$model_layers_5_attention_k_proj_bias

Ä*:
name2
*
("&
$model_layers_5_attention_k_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿°‰À
const>
&model_layers_5_attention_k_proj_weight

Ä
Ä*<
name4
,
*"(
&model_layers_5_attention_k_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄÆ‰π
const5
$model_layers_5_attention_v_proj_bias

Ä*:
name2
*
("&
$model_layers_5_attention_v_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿ÆàÀ
const>
&model_layers_5_attention_v_proj_weight

Ä
Ä*<
name4
,
*"(
&model_layers_5_attention_v_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄªàΩ
const7
&model_layers_5_attention_out_proj_bias

Ä*<
name4
,
*"(
&model_layers_5_attention_out_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿ª¨œ
const@
(model_layers_5_attention_out_proj_weight

Ä
Ä*>
name6
.
,"*
(model_layers_5_attention_out_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄ»¨∑
const4
#model_layers_5_layer_scale1_lambda1

Ä*9
name1
)
'"%
#model_layers_5_layer_scale1_lambda1*=
val6

Ä*%
@model_path/weights/weight.bin¿»–£
const*
model_layers_5_norm2_bias

Ä*/
name'

"
model_layers_5_norm2_bias*=
val6

Ä*%
@model_path/weights/weight.binÄ’–ß
const,
model_layers_5_norm2_weight

Ä*1
name)
!
"
model_layers_5_norm2_weight*=
val6

Ä*%
@model_path/weights/weight.bin¿·–ß
const,
model_layers_5_mlp_fc1_bias

Ä*1
name)
!
"
model_layers_5_mlp_fc1_bias*=
val6

Ä*%
@model_path/weights/weight.binÄÓ–π
const5
model_layers_5_mlp_fc1_weight

Ä
Ä*3
name+
#
!"
model_layers_5_mlp_fc1_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.bin¿û—ß
const,
model_layers_5_mlp_fc2_bias

Ä*1
name)
!
"
model_layers_5_mlp_fc2_bias*=
val6

Ä*%
@model_path/weights/weight.binÄü·π
const5
model_layers_5_mlp_fc2_weight

Ä
Ä*3
name+
#
!"
model_layers_5_mlp_fc2_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.bin¿´·∑
const4
#model_layers_5_layer_scale2_lambda1

Ä*9
name1
)
'"%
#model_layers_5_layer_scale2_lambda1*=
val6

Ä*%
@model_path/weights/weight.binÄ¨Ò£
const*
model_layers_6_norm1_bias

Ä*/
name'

"
model_layers_6_norm1_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿∏Òß
const,
model_layers_6_norm1_weight

Ä*1
name)
!
"
model_layers_6_norm1_weight*=
val6

Ä*%
@model_path/weights/weight.binÄ≈Òπ
const5
$model_layers_6_attention_q_proj_bias

Ä*:
name2
*
("&
$model_layers_6_attention_q_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿—ÒÀ
const>
&model_layers_6_attention_q_proj_weight

Ä
Ä*<
name4
,
*"(
&model_layers_6_attention_q_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄﬁÒπ
const5
$model_layers_6_attention_k_proj_bias

Ä*:
name2
*
("&
$model_layers_6_attention_k_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿ﬁïÀ
const>
&model_layers_6_attention_k_proj_weight

Ä
Ä*<
name4
,
*"(
&model_layers_6_attention_k_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄÎïπ
const5
$model_layers_6_attention_v_proj_bias

Ä*:
name2
*
("&
$model_layers_6_attention_v_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿ÎπÀ
const>
&model_layers_6_attention_v_proj_weight

Ä
Ä*<
name4
,
*"(
&model_layers_6_attention_v_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄ¯πΩ
const7
&model_layers_6_attention_out_proj_bias

Ä*<
name4
,
*"(
&model_layers_6_attention_out_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿¯›œ
const@
(model_layers_6_attention_out_proj_weight

Ä
Ä*>
name6
.
,"*
(model_layers_6_attention_out_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄÖﬁ∑
const4
#model_layers_6_layer_scale1_lambda1

Ä*9
name1
)
'"%
#model_layers_6_layer_scale1_lambda1*=
val6

Ä*%
@model_path/weights/weight.bin¿ÖÇ£
const*
model_layers_6_norm2_bias

Ä*/
name'

"
model_layers_6_norm2_bias*=
val6

Ä*%
@model_path/weights/weight.binÄíÇß
const,
model_layers_6_norm2_weight

Ä*1
name)
!
"
model_layers_6_norm2_weight*=
val6

Ä*%
@model_path/weights/weight.bin¿ûÇß
const,
model_layers_6_mlp_fc1_bias

Ä*1
name)
!
"
model_layers_6_mlp_fc1_bias*=
val6

Ä*%
@model_path/weights/weight.binÄ´Çπ
const5
model_layers_6_mlp_fc1_weight

Ä
Ä*3
name+
#
!"
model_layers_6_mlp_fc1_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.bin¿€Çß
const,
model_layers_6_mlp_fc2_bias

Ä*1
name)
!
"
model_layers_6_mlp_fc2_bias*=
val6

Ä*%
@model_path/weights/weight.binÄ‹íπ
const5
model_layers_6_mlp_fc2_weight

Ä
Ä*3
name+
#
!"
model_layers_6_mlp_fc2_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.bin¿Ëí∑
const4
#model_layers_6_layer_scale2_lambda1

Ä*9
name1
)
'"%
#model_layers_6_layer_scale2_lambda1*=
val6

Ä*%
@model_path/weights/weight.binÄÈ¢£
const*
model_layers_7_norm1_bias

Ä*/
name'

"
model_layers_7_norm1_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿ı¢ß
const,
model_layers_7_norm1_weight

Ä*1
name)
!
"
model_layers_7_norm1_weight*=
val6

Ä*%
@model_path/weights/weight.binÄÇ£π
const5
$model_layers_7_attention_q_proj_bias

Ä*:
name2
*
("&
$model_layers_7_attention_q_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿é£À
const>
&model_layers_7_attention_q_proj_weight

Ä
Ä*<
name4
,
*"(
&model_layers_7_attention_q_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄõ£π
const5
$model_layers_7_attention_k_proj_bias

Ä*:
name2
*
("&
$model_layers_7_attention_k_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿õ«À
const>
&model_layers_7_attention_k_proj_weight

Ä
Ä*<
name4
,
*"(
&model_layers_7_attention_k_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄ®«π
const5
$model_layers_7_attention_v_proj_bias

Ä*:
name2
*
("&
$model_layers_7_attention_v_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿®ÎÀ
const>
&model_layers_7_attention_v_proj_weight

Ä
Ä*<
name4
,
*"(
&model_layers_7_attention_v_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄµÎΩ
const7
&model_layers_7_attention_out_proj_bias

Ä*<
name4
,
*"(
&model_layers_7_attention_out_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿µèœ
const@
(model_layers_7_attention_out_proj_weight

Ä
Ä*>
name6
.
,"*
(model_layers_7_attention_out_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄ¬è∑
const4
#model_layers_7_layer_scale1_lambda1

Ä*9
name1
)
'"%
#model_layers_7_layer_scale1_lambda1*=
val6

Ä*%
@model_path/weights/weight.bin¿¬≥£
const*
model_layers_7_norm2_bias

Ä*/
name'

"
model_layers_7_norm2_bias*=
val6

Ä*%
@model_path/weights/weight.binÄœ≥ß
const,
model_layers_7_norm2_weight

Ä*1
name)
!
"
model_layers_7_norm2_weight*=
val6

Ä*%
@model_path/weights/weight.bin¿€≥ß
const,
model_layers_7_mlp_fc1_bias

Ä*1
name)
!
"
model_layers_7_mlp_fc1_bias*=
val6

Ä*%
@model_path/weights/weight.binÄË≥π
const5
model_layers_7_mlp_fc1_weight

Ä
Ä*3
name+
#
!"
model_layers_7_mlp_fc1_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.bin¿ò¥ß
const,
model_layers_7_mlp_fc2_bias

Ä*1
name)
!
"
model_layers_7_mlp_fc2_bias*=
val6

Ä*%
@model_path/weights/weight.binÄôƒπ
const5
model_layers_7_mlp_fc2_weight

Ä
Ä*3
name+
#
!"
model_layers_7_mlp_fc2_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.bin¿•ƒ∑
const4
#model_layers_7_layer_scale2_lambda1

Ä*9
name1
)
'"%
#model_layers_7_layer_scale2_lambda1*=
val6

Ä*%
@model_path/weights/weight.binÄ¶‘£
const*
model_layers_8_norm1_bias

Ä*/
name'

"
model_layers_8_norm1_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿≤‘ß
const,
model_layers_8_norm1_weight

Ä*1
name)
!
"
model_layers_8_norm1_weight*=
val6

Ä*%
@model_path/weights/weight.binÄø‘π
const5
$model_layers_8_attention_q_proj_bias

Ä*:
name2
*
("&
$model_layers_8_attention_q_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿À‘À
const>
&model_layers_8_attention_q_proj_weight

Ä
Ä*<
name4
,
*"(
&model_layers_8_attention_q_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄÿ‘π
const5
$model_layers_8_attention_k_proj_bias

Ä*:
name2
*
("&
$model_layers_8_attention_k_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿ÿ¯À
const>
&model_layers_8_attention_k_proj_weight

Ä
Ä*<
name4
,
*"(
&model_layers_8_attention_k_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄÂ¯π
const5
$model_layers_8_attention_v_proj_bias

Ä*:
name2
*
("&
$model_layers_8_attention_v_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿ÂúÀ
const>
&model_layers_8_attention_v_proj_weight

Ä
Ä*<
name4
,
*"(
&model_layers_8_attention_v_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄÚúΩ
const7
&model_layers_8_attention_out_proj_bias

Ä*<
name4
,
*"(
&model_layers_8_attention_out_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿Ú¿œ
const@
(model_layers_8_attention_out_proj_weight

Ä
Ä*>
name6
.
,"*
(model_layers_8_attention_out_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄˇ¿∑
const4
#model_layers_8_layer_scale1_lambda1

Ä*9
name1
)
'"%
#model_layers_8_layer_scale1_lambda1*=
val6

Ä*%
@model_path/weights/weight.bin¿ˇ‰£
const*
model_layers_8_norm2_bias

Ä*/
name'

"
model_layers_8_norm2_bias*=
val6

Ä*%
@model_path/weights/weight.binÄåÂß
const,
model_layers_8_norm2_weight

Ä*1
name)
!
"
model_layers_8_norm2_weight*=
val6

Ä*%
@model_path/weights/weight.bin¿òÂß
const,
model_layers_8_mlp_fc1_bias

Ä*1
name)
!
"
model_layers_8_mlp_fc1_bias*=
val6

Ä*%
@model_path/weights/weight.binÄ•Âπ
const5
model_layers_8_mlp_fc1_weight

Ä
Ä*3
name+
#
!"
model_layers_8_mlp_fc1_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.bin¿’Âß
const,
model_layers_8_mlp_fc2_bias

Ä*1
name)
!
"
model_layers_8_mlp_fc2_bias*=
val6

Ä*%
@model_path/weights/weight.binÄ÷ıπ
const5
model_layers_8_mlp_fc2_weight

Ä
Ä*3
name+
#
!"
model_layers_8_mlp_fc2_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.bin¿‚ı∑
const4
#model_layers_8_layer_scale2_lambda1

Ä*9
name1
)
'"%
#model_layers_8_layer_scale2_lambda1*=
val6

Ä*%
@model_path/weights/weight.binÄ„Ö£
const*
model_layers_9_norm1_bias

Ä*/
name'

"
model_layers_9_norm1_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿ÔÖß
const,
model_layers_9_norm1_weight

Ä*1
name)
!
"
model_layers_9_norm1_weight*=
val6

Ä*%
@model_path/weights/weight.binÄ¸Öπ
const5
$model_layers_9_attention_q_proj_bias

Ä*:
name2
*
("&
$model_layers_9_attention_q_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿àÜÀ
const>
&model_layers_9_attention_q_proj_weight

Ä
Ä*<
name4
,
*"(
&model_layers_9_attention_q_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄïÜπ
const5
$model_layers_9_attention_k_proj_bias

Ä*:
name2
*
("&
$model_layers_9_attention_k_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿ï™À
const>
&model_layers_9_attention_k_proj_weight

Ä
Ä*<
name4
,
*"(
&model_layers_9_attention_k_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄ¢™π
const5
$model_layers_9_attention_v_proj_bias

Ä*:
name2
*
("&
$model_layers_9_attention_v_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿¢ŒÀ
const>
&model_layers_9_attention_v_proj_weight

Ä
Ä*<
name4
,
*"(
&model_layers_9_attention_v_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄØŒΩ
const7
&model_layers_9_attention_out_proj_bias

Ä*<
name4
,
*"(
&model_layers_9_attention_out_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿ØÚœ
const@
(model_layers_9_attention_out_proj_weight

Ä
Ä*>
name6
.
,"*
(model_layers_9_attention_out_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄºÚ∑
const4
#model_layers_9_layer_scale1_lambda1

Ä*9
name1
)
'"%
#model_layers_9_layer_scale1_lambda1*=
val6

Ä*%
@model_path/weights/weight.bin¿ºñ £
const*
model_layers_9_norm2_bias

Ä*/
name'

"
model_layers_9_norm2_bias*=
val6

Ä*%
@model_path/weights/weight.binÄ…ñ ß
const,
model_layers_9_norm2_weight

Ä*1
name)
!
"
model_layers_9_norm2_weight*=
val6

Ä*%
@model_path/weights/weight.bin¿’ñ ß
const,
model_layers_9_mlp_fc1_bias

Ä*1
name)
!
"
model_layers_9_mlp_fc1_bias*=
val6

Ä*%
@model_path/weights/weight.binÄ‚ñ π
const5
model_layers_9_mlp_fc1_weight

Ä
Ä*3
name+
#
!"
model_layers_9_mlp_fc1_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.bin¿íó ß
const,
model_layers_9_mlp_fc2_bias

Ä*1
name)
!
"
model_layers_9_mlp_fc2_bias*=
val6

Ä*%
@model_path/weights/weight.binÄìß!π
const5
model_layers_9_mlp_fc2_weight

Ä
Ä*3
name+
#
!"
model_layers_9_mlp_fc2_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.bin¿üß!∑
const4
#model_layers_9_layer_scale2_lambda1

Ä*9
name1
)
'"%
#model_layers_9_layer_scale2_lambda1*=
val6

Ä*%
@model_path/weights/weight.binÄ†∑"•
const+
model_layers_10_norm1_bias

Ä*0
name(
 
"
model_layers_10_norm1_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿¨∑"©
const-
model_layers_10_norm1_weight

Ä*2
name*
"
 "
model_layers_10_norm1_weight*=
val6

Ä*%
@model_path/weights/weight.binÄπ∑"ª
const6
%model_layers_10_attention_q_proj_bias

Ä*;
name3
+
)"'
%model_layers_10_attention_q_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿≈∑"Õ
const?
'model_layers_10_attention_q_proj_weight

Ä
Ä*=
name5
-
+")
'model_layers_10_attention_q_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄ“∑"ª
const6
%model_layers_10_attention_k_proj_bias

Ä*;
name3
+
)"'
%model_layers_10_attention_k_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿“€"Õ
const?
'model_layers_10_attention_k_proj_weight

Ä
Ä*=
name5
-
+")
'model_layers_10_attention_k_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄﬂ€"ª
const6
%model_layers_10_attention_v_proj_bias

Ä*;
name3
+
)"'
%model_layers_10_attention_v_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿ﬂˇ"Õ
const?
'model_layers_10_attention_v_proj_weight

Ä
Ä*=
name5
-
+")
'model_layers_10_attention_v_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄÏˇ"ø
const8
'model_layers_10_attention_out_proj_bias

Ä*=
name5
-
+")
'model_layers_10_attention_out_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿Ï£#—
constA
)model_layers_10_attention_out_proj_weight

Ä
Ä*?
name7
/
-"+
)model_layers_10_attention_out_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄ˘£#π
const5
$model_layers_10_layer_scale1_lambda1

Ä*:
name2
*
("&
$model_layers_10_layer_scale1_lambda1*=
val6

Ä*%
@model_path/weights/weight.bin¿˘«#•
const+
model_layers_10_norm2_bias

Ä*0
name(
 
"
model_layers_10_norm2_bias*=
val6

Ä*%
@model_path/weights/weight.binÄÜ»#©
const-
model_layers_10_norm2_weight

Ä*2
name*
"
 "
model_layers_10_norm2_weight*=
val6

Ä*%
@model_path/weights/weight.bin¿í»#©
const-
model_layers_10_mlp_fc1_bias

Ä*2
name*
"
 "
model_layers_10_mlp_fc1_bias*=
val6

Ä*%
@model_path/weights/weight.binÄü»#ª
const6
model_layers_10_mlp_fc1_weight

Ä
Ä*4
name,
$
"" 
model_layers_10_mlp_fc1_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.bin¿œ»#©
const-
model_layers_10_mlp_fc2_bias

Ä*2
name*
"
 "
model_layers_10_mlp_fc2_bias*=
val6

Ä*%
@model_path/weights/weight.binÄ–ÿ$ª
const6
model_layers_10_mlp_fc2_weight

Ä
Ä*4
name,
$
"" 
model_layers_10_mlp_fc2_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.bin¿‹ÿ$π
const5
$model_layers_10_layer_scale2_lambda1

Ä*:
name2
*
("&
$model_layers_10_layer_scale2_lambda1*=
val6

Ä*%
@model_path/weights/weight.binÄ›Ë%•
const+
model_layers_11_norm1_bias

Ä*0
name(
 
"
model_layers_11_norm1_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿ÈË%©
const-
model_layers_11_norm1_weight

Ä*2
name*
"
 "
model_layers_11_norm1_weight*=
val6

Ä*%
@model_path/weights/weight.binÄˆË%ª
const6
%model_layers_11_attention_q_proj_bias

Ä*;
name3
+
)"'
%model_layers_11_attention_q_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿ÇÈ%Õ
const?
'model_layers_11_attention_q_proj_weight

Ä
Ä*=
name5
-
+")
'model_layers_11_attention_q_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄèÈ%ª
const6
%model_layers_11_attention_k_proj_bias

Ä*;
name3
+
)"'
%model_layers_11_attention_k_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿èç&Õ
const?
'model_layers_11_attention_k_proj_weight

Ä
Ä*=
name5
-
+")
'model_layers_11_attention_k_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄúç&ª
const6
%model_layers_11_attention_v_proj_bias

Ä*;
name3
+
)"'
%model_layers_11_attention_v_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿ú±&Õ
const?
'model_layers_11_attention_v_proj_weight

Ä
Ä*=
name5
-
+")
'model_layers_11_attention_v_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄ©±&ø
const8
'model_layers_11_attention_out_proj_bias

Ä*=
name5
-
+")
'model_layers_11_attention_out_proj_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿©’&—
constA
)model_layers_11_attention_out_proj_weight

Ä
Ä*?
name7
/
-"+
)model_layers_11_attention_out_proj_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.binÄ∂’&π
const5
$model_layers_11_layer_scale1_lambda1

Ä*:
name2
*
("&
$model_layers_11_layer_scale1_lambda1*=
val6

Ä*%
@model_path/weights/weight.bin¿∂˘&•
const+
model_layers_11_norm2_bias

Ä*0
name(
 
"
model_layers_11_norm2_bias*=
val6

Ä*%
@model_path/weights/weight.binÄ√˘&©
const-
model_layers_11_norm2_weight

Ä*2
name*
"
 "
model_layers_11_norm2_weight*=
val6

Ä*%
@model_path/weights/weight.bin¿œ˘&©
const-
model_layers_11_mlp_fc1_bias

Ä*2
name*
"
 "
model_layers_11_mlp_fc1_bias*=
val6

Ä*%
@model_path/weights/weight.binÄ‹˘&ª
const6
model_layers_11_mlp_fc1_weight

Ä
Ä*4
name,
$
"" 
model_layers_11_mlp_fc1_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.bin¿å˙&©
const-
model_layers_11_mlp_fc2_bias

Ä*2
name*
"
 "
model_layers_11_mlp_fc2_bias*=
val6

Ä*%
@model_path/weights/weight.binÄçä(ª
const6
model_layers_11_mlp_fc2_weight

Ä
Ä*4
name,
$
"" 
model_layers_11_mlp_fc2_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.bin¿ôä(π
const5
$model_layers_11_layer_scale2_lambda1

Ä*:
name2
*
("&
$model_layers_11_layer_scale2_lambda1*=
val6

Ä*%
@model_path/weights/weight.binÄöö)ô
const%
model_layernorm_bias

Ä**
name"

"
model_layernorm_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿¶ö)ù
const'
model_layernorm_weight

Ä*,
name$

"
model_layernorm_weight*=
val6

Ä*%
@model_path/weights/weight.binÄ≥ö)•
const+
model_class_predictor_bias

Ü*0
name(
 
"
model_class_predictor_bias*=
val6

Ü*%
@model_path/weights/weight.bin¿øö)∑
const4
model_class_predictor_weight

Ü
Ä*2
name*
"
 "
model_class_predictor_weight*D
val=

Ü
Ä*%
@model_path/weights/weight.bin¿ƒö)°
const)
model_mask_head_fc1_bias

Ä*.
name&

"
model_mask_head_fc1_bias*=
val6

Ä*%
@model_path/weights/weight.binÄçß)≥
const2
model_mask_head_fc1_weight

Ä
Ä*0
name(
 
"
model_mask_head_fc1_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.bin¿ôß)°
const)
model_mask_head_fc2_bias

Ä*.
name&

"
model_mask_head_fc2_bias*=
val6

Ä*%
@model_path/weights/weight.binÄöÀ)≥
const2
model_mask_head_fc2_weight

Ä
Ä*0
name(
 
"
model_mask_head_fc2_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.bin¿¶À)°
const)
model_mask_head_fc3_bias

Ä*.
name&

"
model_mask_head_fc3_bias*=
val6

Ä*%
@model_path/weights/weight.binÄßÔ)≥
const2
model_mask_head_fc3_weight

Ä
Ä*0
name(
 
"
model_mask_head_fc3_weight*D
val=

Ä
Ä*%
@model_path/weights/weight.bin¿≥Ô)Ω
const7
&model_upscale_block_block_0_conv1_bias

Ä*<
name4
,
*"(
&model_upscale_block_block_0_conv1_bias*=
val6

Ä*%
@model_path/weights/weight.binÄ¥ì*Á
constL
(model_upscale_block_block_0_conv1_weight 

Ä
Ä

*>
name6
.
,"*
(model_upscale_block_block_0_conv1_weight*P
valI 

Ä
Ä

*%
@model_path/weights/weight.bin¿¿ì*Â
constK
(model_upscale_block_block_0_conv2_weight

Ä


*>
name6
.
,"*
(model_upscale_block_block_0_conv2_weight*O
valH

Ä


*%
@model_path/weights/weight.binÄ¡£+…
const=
,model_upscale_block_block_0_layernorm2d_bias

Ä*B
name:
2
0".
,model_upscale_block_block_0_layernorm2d_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿≠§+Õ
const?
.model_upscale_block_block_0_layernorm2d_weight

Ä*D
name<
4
2"0
.model_upscale_block_block_0_layernorm2d_weight*=
val6

Ä*%
@model_path/weights/weight.binÄ∫§+Ω
const7
&model_upscale_block_block_1_conv1_bias

Ä*<
name4
,
*"(
&model_upscale_block_block_1_conv1_bias*=
val6

Ä*%
@model_path/weights/weight.bin¿∆§+Á
constL
(model_upscale_block_block_1_conv1_weight 

Ä
Ä

*>
name6
.
,"*
(model_upscale_block_block_1_conv1_weight*P
valI 

Ä
Ä

*%
@model_path/weights/weight.binÄ”§+Â
constK
(model_upscale_block_block_1_conv2_weight

Ä


*>
name6
.
,"*
(model_upscale_block_block_1_conv2_weight*O
valH

Ä


*%
@model_path/weights/weight.bin¿”¥,…
const=
,model_upscale_block_block_1_layernorm2d_bias

Ä*B
name:
2
0".
,model_upscale_block_block_1_layernorm2d_bias*=
val6

Ä*%
@model_path/weights/weight.binÄ¿µ,Õ
const?
.model_upscale_block_block_1_layernorm2d_weight

Ä*D
name<
4
2"0
.model_upscale_block_block_1_layernorm2d_weight*=
val6

Ä*%
@model_path/weights/weight.bin¿Ãµ,O
const
var_10
*
name

	"
op_10*
val




Ω7Ü5O
const
var_12
*
name

	"
op_12*
val




   >L
const
var_22
*
name

	"
op_22*
val


f
const
var_70_pad_type_0
*&
name

"
op_70_pad_type_0*
val

	"
validq
const 
var_70_strides_0


*%
name

"
op_70_strides_0*
val




k
const
var_70_pad_0


*!
name

"
op_70_pad_0*!
val





    u
const"
var_70_dilations_0


*'
name

"
op_70_dilations_0*
val




^
const
var_70_groups_0
*$
name

"
op_70_groups_0*
val


í
conv#
	dilations

var_70_dilations_0A
weight7
5
3model_embeddings_patch_embeddings_projection_weight
pad

var_70_pad_0
groups

var_70_groups_0
x

pixel_values__biased__
strides

var_70_strides_0=
bias5
3
1model_embeddings_patch_embeddings_projection_bias!
pad_type

var_70_pad_type_0)
var_70


Ä
(
(*
name

	"
op_70e
const
concat_0


*
name

"

concat_0*"
val



	
Ä¿t
reshape
x


var_70
shape


concat_0$
var_71


Ä
¿*
name

	"
op_71y
const#
embeddings_1_perm_0


*)
name!

"
embeddings_1_perm_0* 
val


	

 ñ
const$
var_78


¿
Ä*
name

	"
op_78*J
valC


¿
Ä*%
@model_path/weights/weight.binÄŸµ,é
	transpose
perm

embeddings_1_perm_0
x


var_71*
embeddings_1


¿
Ä*#
name

"
transpose_128}
add
x

embeddings_1
y


var_78*
embeddings_3


¿
Ä*"
name

"
embeddings_3i
const
input_3_interleave_0
**
name"

"
input_3_interleave_0*
val


 Ë
concat
axis


var_22&

interleave

input_3_interleave_0\
valuesR

model_embeddings_cls_token
"
 model_embeddings_register_tokens

embeddings_3%
input_3


≈
Ä*
name

"	
input_3Ü
const&
hidden_states_1_axes_0


*,
name$

"
hidden_states_1_axes_0*'
val 





ˇˇˇˇˇˇˇˇˇÄ

layer_norm
epsilon


var_10%
beta

model_layers_0_norm1_bias
x
	
input_3(
gamma

model_layers_0_norm1_weight"
axes

hidden_states_1_axes_0-
hidden_states_1


≈
Ä*%
name

"
hidden_states_1”
linear
x

hidden_states_10
bias(
&
$model_layers_0_attention_q_proj_bias4
weight*
(
&model_layers_0_attention_q_proj_weight'
	queries_1


≈
Ä*
name

"

linear_0–
linear
x

hidden_states_10
bias(
&
$model_layers_0_attention_k_proj_bias4
weight*
(
&model_layers_0_attention_k_proj_weight$
keys_1


≈
Ä*
name

"

linear_1“
linear
x

hidden_states_10
bias(
&
$model_layers_0_attention_v_proj_bias4
weight*
(
&model_layers_0_attention_v_proj_weight&
values_1


≈
Ä*
name

"

linear_2b
const
var_109


*
name


"
op_109*"
val



	
≈@}
reshape
x

	queries_1
shape
	
var_109*
var_110


≈

@*
name


"
op_110b
const
var_112


*
name


"
op_112*"
val



	
≈@z
reshape
x


keys_1
shape
	
var_112*
var_113


≈

@*
name


"
op_113b
const
var_115


*
name


"
op_115*"
val



	
≈@|
reshape
x


values_1
shape
	
var_115*
var_116


≈

@*
name


"
op_116p
const
value_1_perm_0


*$
name

"
value_1_perm_0*!
val





 o
mul
x
	
var_110
y


var_12(
mul_0


≈

@*
name

	"
mul_0m
const
matmul_0_transpose_y_0
*,
name$

"
matmul_0_transpose_y_0*
val


m
const
matmul_0_transpose_x_0
*,
name$

"
matmul_0_transpose_x_0*
val


 å
const#
transpose_50_perm_0


*)
name!

"
transpose_50_perm_0*3
val,




 ˝ˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇå
const#
transpose_51_perm_0


*)
name!

"
transpose_51_perm_0*3
val,




 ˝ˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇî
	transpose
perm

transpose_51_perm_0
x
	
var_113/
transpose_51



≈
@*#
name

"
transpose_125í
	transpose
perm

transpose_50_perm_0
x	

mul_0/
transpose_50



≈
@*#
name

"
transpose_126⁄
matmul)
transpose_y

matmul_0_transpose_y_0
x

transpose_50
y

transpose_51)
transpose_x

matmul_0_transpose_x_0,
matmul_0 



≈
≈*
name

"

matmul_0j
const
softmax_0_axis_0
*&
name

"
softmax_0_axis_0*
val



ˇˇˇˇˇˇˇˇˇä
softmax
axis

softmax_0_axis_0
x


matmul_0-
	softmax_0 



≈
≈*
name

"
	softmax_0w
const#
attn_output_1_transpose_x_0
*1
name)
!
"
attn_output_1_transpose_x_0*
val


 w
const#
attn_output_1_transpose_y_0
*1
name)
!
"
attn_output_1_transpose_y_0*
val


 ä
	transpose
perm

value_1_perm_0
x
	
var_116*
value_1



≈
@*#
name

"
transpose_127Â
matmul.
transpose_y

attn_output_1_transpose_y_0
x

	softmax_0
y
	
value_1.
transpose_x

attn_output_1_transpose_x_00
attn_output_1



≈
@*#
name

"
attn_output_1o
const
var_119_perm_0


*#
name

"
op_119_perm_0*!
val





 b
const
var_121


*
name


"
op_121*"
val



	
≈Äê
	transpose
perm

var_119_perm_0
x

attn_output_1*
var_119


≈

@*#
name

"
transpose_124v
reshape
x
	
var_119
shape
	
var_121%
var_122


≈
Ä*
name


"
op_122‘
linear
x
	
var_1222
bias*
(
&model_layers_0_attention_out_proj_bias6
weight,
*
(model_layers_0_attention_out_proj_weight,
hidden_state_1


≈
Ä*
name

"

linear_3≤
mul
x

hidden_state_1,
y'
%
#model_layers_0_layer_scale1_lambda15
self_attention_output_1


≈
Ä*-
name%

"
self_attention_output_1
add 
x

self_attention_output_1
y
	
input_3%
input_9


≈
Ä*
name

"	
input_9x
const
input_11_axes_0


*%
name

"
input_11_axes_0*'
val 





ˇˇˇˇˇˇˇˇˇÎ

layer_norm
epsilon


var_10%
beta

model_layers_0_norm2_bias
x
	
input_9(
gamma

model_layers_0_norm2_weight
axes

input_11_axes_0&
input_11


≈
Ä*
name

"

input_11π
linear
x


input_11'
bias

model_layers_0_mlp_fc1_bias+
weight!

model_layers_0_mlp_fc1_weight&
input_13


≈
Ä*
name

"

linear_4c
const
input_15_mode_0
*%
name

"
input_15_mode_0*
val

	"
EXACT~
gelu
x


input_13
mode

input_15_mode_0&
input_15


≈
Ä*
name

"

input_15ø
linear
x


input_15'
bias

model_layers_0_mlp_fc2_bias+
weight!

model_layers_0_mlp_fc2_weight,
hidden_state_3


≈
Ä*
name

"

linear_5†
mul
x

hidden_state_3,
y'
%
#model_layers_0_layer_scale2_lambda1,
layer_output_1


≈
Ä*$
name

"
layer_output_1x
add
x

layer_output_1
y
	
input_9&
input_17


≈
Ä*
name

"

input_17Ü
const&
hidden_states_3_axes_0


*,
name$

"
hidden_states_3_axes_0*'
val 





ˇˇˇˇˇˇˇˇˇÅ

layer_norm
epsilon


var_10%
beta

model_layers_1_norm1_bias
x


input_17(
gamma

model_layers_1_norm1_weight"
axes

hidden_states_3_axes_0-
hidden_states_3


≈
Ä*%
name

"
hidden_states_3”
linear
x

hidden_states_30
bias(
&
$model_layers_1_attention_q_proj_bias4
weight*
(
&model_layers_1_attention_q_proj_weight'
	queries_3


≈
Ä*
name

"

linear_6–
linear
x

hidden_states_30
bias(
&
$model_layers_1_attention_k_proj_bias4
weight*
(
&model_layers_1_attention_k_proj_weight$
keys_3


≈
Ä*
name

"

linear_7“
linear
x

hidden_states_30
bias(
&
$model_layers_1_attention_v_proj_bias4
weight*
(
&model_layers_1_attention_v_proj_weight&
values_3


≈
Ä*
name

"

linear_8b
const
var_172


*
name


"
op_172*"
val



	
≈@}
reshape
x

	queries_3
shape
	
var_172*
var_173


≈

@*
name


"
op_173b
const
var_175


*
name


"
op_175*"
val



	
≈@z
reshape
x


keys_3
shape
	
var_175*
var_176


≈

@*
name


"
op_176b
const
var_178


*
name


"
op_178*"
val



	
≈@|
reshape
x


values_3
shape
	
var_178*
var_179


≈

@*
name


"
op_179p
const
value_3_perm_0


*$
name

"
value_3_perm_0*!
val





 o
mul
x
	
var_173
y


var_12(
mul_1


≈

@*
name

	"
mul_1m
const
matmul_1_transpose_y_0
*,
name$

"
matmul_1_transpose_y_0*
val


m
const
matmul_1_transpose_x_0
*,
name$

"
matmul_1_transpose_x_0*
val


 å
const#
transpose_52_perm_0


*)
name!

"
transpose_52_perm_0*3
val,




 ˝ˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇå
const#
transpose_53_perm_0


*)
name!

"
transpose_53_perm_0*3
val,




 ˝ˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇî
	transpose
perm

transpose_53_perm_0
x
	
var_176/
transpose_53



≈
@*#
name

"
transpose_121í
	transpose
perm

transpose_52_perm_0
x	

mul_1/
transpose_52



≈
@*#
name

"
transpose_122⁄
matmul)
transpose_y

matmul_1_transpose_y_0
x

transpose_52
y

transpose_53)
transpose_x

matmul_1_transpose_x_0,
matmul_1 



≈
≈*
name

"

matmul_1j
const
softmax_1_axis_0
*&
name

"
softmax_1_axis_0*
val



ˇˇˇˇˇˇˇˇˇä
softmax
axis

softmax_1_axis_0
x


matmul_1-
	softmax_1 



≈
≈*
name

"
	softmax_1w
const#
attn_output_5_transpose_x_0
*1
name)
!
"
attn_output_5_transpose_x_0*
val


 w
const#
attn_output_5_transpose_y_0
*1
name)
!
"
attn_output_5_transpose_y_0*
val


 ä
	transpose
perm

value_3_perm_0
x
	
var_179*
value_3



≈
@*#
name

"
transpose_123Â
matmul.
transpose_y

attn_output_5_transpose_y_0
x

	softmax_1
y
	
value_3.
transpose_x

attn_output_5_transpose_x_00
attn_output_5



≈
@*#
name

"
attn_output_5o
const
var_182_perm_0


*#
name

"
op_182_perm_0*!
val





 b
const
var_184


*
name


"
op_184*"
val



	
≈Äê
	transpose
perm

var_182_perm_0
x

attn_output_5*
var_182


≈

@*#
name

"
transpose_120v
reshape
x
	
var_182
shape
	
var_184%
var_185


≈
Ä*
name


"
op_185‘
linear
x
	
var_1852
bias*
(
&model_layers_1_attention_out_proj_bias6
weight,
*
(model_layers_1_attention_out_proj_weight,
hidden_state_5


≈
Ä*
name

"

linear_9≤
mul
x

hidden_state_5,
y'
%
#model_layers_1_layer_scale1_lambda15
self_attention_output_3


≈
Ä*-
name%

"
self_attention_output_3Ç
add 
x

self_attention_output_3
y


input_17&
input_21


≈
Ä*
name

"

input_21x
const
input_23_axes_0


*%
name

"
input_23_axes_0*'
val 





ˇˇˇˇˇˇˇˇˇÏ

layer_norm
epsilon


var_10%
beta

model_layers_1_norm2_bias
x


input_21(
gamma

model_layers_1_norm2_weight
axes

input_23_axes_0&
input_23


≈
Ä*
name

"

input_23∫
linear
x


input_23'
bias

model_layers_1_mlp_fc1_bias+
weight!

model_layers_1_mlp_fc1_weight&
input_25


≈
Ä*
name

"
	linear_10c
const
input_27_mode_0
*%
name

"
input_27_mode_0*
val

	"
EXACT~
gelu
x


input_25
mode

input_27_mode_0&
input_27


≈
Ä*
name

"

input_27¿
linear
x


input_27'
bias

model_layers_1_mlp_fc2_bias+
weight!

model_layers_1_mlp_fc2_weight,
hidden_state_7


≈
Ä*
name

"
	linear_11†
mul
x

hidden_state_7,
y'
%
#model_layers_1_layer_scale2_lambda1,
layer_output_3


≈
Ä*$
name

"
layer_output_3y
add
x

layer_output_3
y


input_21&
input_29


≈
Ä*
name

"

input_29Ü
const&
hidden_states_5_axes_0


*,
name$

"
hidden_states_5_axes_0*'
val 





ˇˇˇˇˇˇˇˇˇÅ

layer_norm
epsilon


var_10%
beta

model_layers_2_norm1_bias
x


input_29(
gamma

model_layers_2_norm1_weight"
axes

hidden_states_5_axes_0-
hidden_states_5


≈
Ä*%
name

"
hidden_states_5‘
linear
x

hidden_states_50
bias(
&
$model_layers_2_attention_q_proj_bias4
weight*
(
&model_layers_2_attention_q_proj_weight'
	queries_5


≈
Ä*
name

"
	linear_12—
linear
x

hidden_states_50
bias(
&
$model_layers_2_attention_k_proj_bias4
weight*
(
&model_layers_2_attention_k_proj_weight$
keys_5


≈
Ä*
name

"
	linear_13”
linear
x

hidden_states_50
bias(
&
$model_layers_2_attention_v_proj_bias4
weight*
(
&model_layers_2_attention_v_proj_weight&
values_5


≈
Ä*
name

"
	linear_14b
const
var_235


*
name


"
op_235*"
val



	
≈@}
reshape
x

	queries_5
shape
	
var_235*
var_236


≈

@*
name


"
op_236b
const
var_238


*
name


"
op_238*"
val



	
≈@z
reshape
x


keys_5
shape
	
var_238*
var_239


≈

@*
name


"
op_239b
const
var_241


*
name


"
op_241*"
val



	
≈@|
reshape
x


values_5
shape
	
var_241*
var_242


≈

@*
name


"
op_242p
const
value_5_perm_0


*$
name

"
value_5_perm_0*!
val





 o
mul
x
	
var_236
y


var_12(
mul_2


≈

@*
name

	"
mul_2m
const
matmul_2_transpose_y_0
*,
name$

"
matmul_2_transpose_y_0*
val


m
const
matmul_2_transpose_x_0
*,
name$

"
matmul_2_transpose_x_0*
val


 å
const#
transpose_54_perm_0


*)
name!

"
transpose_54_perm_0*3
val,




 ˝ˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇå
const#
transpose_55_perm_0


*)
name!

"
transpose_55_perm_0*3
val,




 ˝ˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇî
	transpose
perm

transpose_55_perm_0
x
	
var_239/
transpose_55



≈
@*#
name

"
transpose_117í
	transpose
perm

transpose_54_perm_0
x	

mul_2/
transpose_54



≈
@*#
name

"
transpose_118⁄
matmul)
transpose_y

matmul_2_transpose_y_0
x

transpose_54
y

transpose_55)
transpose_x

matmul_2_transpose_x_0,
matmul_2 



≈
≈*
name

"

matmul_2j
const
softmax_2_axis_0
*&
name

"
softmax_2_axis_0*
val



ˇˇˇˇˇˇˇˇˇä
softmax
axis

softmax_2_axis_0
x


matmul_2-
	softmax_2 



≈
≈*
name

"
	softmax_2w
const#
attn_output_9_transpose_x_0
*1
name)
!
"
attn_output_9_transpose_x_0*
val


 w
const#
attn_output_9_transpose_y_0
*1
name)
!
"
attn_output_9_transpose_y_0*
val


 ä
	transpose
perm

value_5_perm_0
x
	
var_242*
value_5



≈
@*#
name

"
transpose_119Â
matmul.
transpose_y

attn_output_9_transpose_y_0
x

	softmax_2
y
	
value_5.
transpose_x

attn_output_9_transpose_x_00
attn_output_9



≈
@*#
name

"
attn_output_9o
const
var_245_perm_0


*#
name

"
op_245_perm_0*!
val





 b
const
var_247


*
name


"
op_247*"
val



	
≈Äê
	transpose
perm

var_245_perm_0
x

attn_output_9*
var_245


≈

@*#
name

"
transpose_116v
reshape
x
	
var_245
shape
	
var_247%
var_248


≈
Ä*
name


"
op_248’
linear
x
	
var_2482
bias*
(
&model_layers_2_attention_out_proj_bias6
weight,
*
(model_layers_2_attention_out_proj_weight,
hidden_state_9


≈
Ä*
name

"
	linear_15≤
mul
x

hidden_state_9,
y'
%
#model_layers_2_layer_scale1_lambda15
self_attention_output_5


≈
Ä*-
name%

"
self_attention_output_5Ç
add 
x

self_attention_output_5
y


input_29&
input_33


≈
Ä*
name

"

input_33x
const
input_35_axes_0


*%
name

"
input_35_axes_0*'
val 





ˇˇˇˇˇˇˇˇˇÏ

layer_norm
epsilon


var_10%
beta

model_layers_2_norm2_bias
x


input_33(
gamma

model_layers_2_norm2_weight
axes

input_35_axes_0&
input_35


≈
Ä*
name

"

input_35∫
linear
x


input_35'
bias

model_layers_2_mlp_fc1_bias+
weight!

model_layers_2_mlp_fc1_weight&
input_37


≈
Ä*
name

"
	linear_16c
const
input_39_mode_0
*%
name

"
input_39_mode_0*
val

	"
EXACT~
gelu
x


input_37
mode

input_39_mode_0&
input_39


≈
Ä*
name

"

input_39¡
linear
x


input_39'
bias

model_layers_2_mlp_fc2_bias+
weight!

model_layers_2_mlp_fc2_weight-
hidden_state_11


≈
Ä*
name

"
	linear_17°
mul
x

hidden_state_11,
y'
%
#model_layers_2_layer_scale2_lambda1,
layer_output_5


≈
Ä*$
name

"
layer_output_5y
add
x

layer_output_5
y


input_33&
input_41


≈
Ä*
name

"

input_41Ü
const&
hidden_states_7_axes_0


*,
name$

"
hidden_states_7_axes_0*'
val 





ˇˇˇˇˇˇˇˇˇÅ

layer_norm
epsilon


var_10%
beta

model_layers_3_norm1_bias
x


input_41(
gamma

model_layers_3_norm1_weight"
axes

hidden_states_7_axes_0-
hidden_states_7


≈
Ä*%
name

"
hidden_states_7‘
linear
x

hidden_states_70
bias(
&
$model_layers_3_attention_q_proj_bias4
weight*
(
&model_layers_3_attention_q_proj_weight'
	queries_7


≈
Ä*
name

"
	linear_18—
linear
x

hidden_states_70
bias(
&
$model_layers_3_attention_k_proj_bias4
weight*
(
&model_layers_3_attention_k_proj_weight$
keys_7


≈
Ä*
name

"
	linear_19”
linear
x

hidden_states_70
bias(
&
$model_layers_3_attention_v_proj_bias4
weight*
(
&model_layers_3_attention_v_proj_weight&
values_7


≈
Ä*
name

"
	linear_20b
const
var_298


*
name


"
op_298*"
val



	
≈@}
reshape
x

	queries_7
shape
	
var_298*
var_299


≈

@*
name


"
op_299b
const
var_301


*
name


"
op_301*"
val



	
≈@z
reshape
x


keys_7
shape
	
var_301*
var_302


≈

@*
name


"
op_302b
const
var_304


*
name


"
op_304*"
val



	
≈@|
reshape
x


values_7
shape
	
var_304*
var_305


≈

@*
name


"
op_305p
const
value_7_perm_0


*$
name

"
value_7_perm_0*!
val





 o
mul
x
	
var_299
y


var_12(
mul_3


≈

@*
name

	"
mul_3m
const
matmul_3_transpose_y_0
*,
name$

"
matmul_3_transpose_y_0*
val


m
const
matmul_3_transpose_x_0
*,
name$

"
matmul_3_transpose_x_0*
val


 å
const#
transpose_56_perm_0


*)
name!

"
transpose_56_perm_0*3
val,




 ˝ˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇå
const#
transpose_57_perm_0


*)
name!

"
transpose_57_perm_0*3
val,




 ˝ˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇî
	transpose
perm

transpose_57_perm_0
x
	
var_302/
transpose_57



≈
@*#
name

"
transpose_113í
	transpose
perm

transpose_56_perm_0
x	

mul_3/
transpose_56



≈
@*#
name

"
transpose_114⁄
matmul)
transpose_y

matmul_3_transpose_y_0
x

transpose_56
y

transpose_57)
transpose_x

matmul_3_transpose_x_0,
matmul_3 



≈
≈*
name

"

matmul_3j
const
softmax_3_axis_0
*&
name

"
softmax_3_axis_0*
val



ˇˇˇˇˇˇˇˇˇä
softmax
axis

softmax_3_axis_0
x


matmul_3-
	softmax_3 



≈
≈*
name

"
	softmax_3y
const$
attn_output_13_transpose_x_0
*2
name*
"
 "
attn_output_13_transpose_x_0*
val


 y
const$
attn_output_13_transpose_y_0
*2
name*
"
 "
attn_output_13_transpose_y_0*
val


 ä
	transpose
perm

value_7_perm_0
x
	
var_305*
value_7



≈
@*#
name

"
transpose_115È
matmul/
transpose_y 

attn_output_13_transpose_y_0
x

	softmax_3
y
	
value_7/
transpose_x 

attn_output_13_transpose_x_01
attn_output_13



≈
@*$
name

"
attn_output_13o
const
var_308_perm_0


*#
name

"
op_308_perm_0*!
val





 b
const
var_310


*
name


"
op_310*"
val



	
≈Äë
	transpose
perm

var_308_perm_0
x

attn_output_13*
var_308


≈

@*#
name

"
transpose_112v
reshape
x
	
var_308
shape
	
var_310%
var_311


≈
Ä*
name


"
op_311÷
linear
x
	
var_3112
bias*
(
&model_layers_3_attention_out_proj_bias6
weight,
*
(model_layers_3_attention_out_proj_weight-
hidden_state_13


≈
Ä*
name

"
	linear_21≥
mul
x

hidden_state_13,
y'
%
#model_layers_3_layer_scale1_lambda15
self_attention_output_7


≈
Ä*-
name%

"
self_attention_output_7Ç
add 
x

self_attention_output_7
y


input_41&
input_45


≈
Ä*
name

"

input_45x
const
input_47_axes_0


*%
name

"
input_47_axes_0*'
val 





ˇˇˇˇˇˇˇˇˇÏ

layer_norm
epsilon


var_10%
beta

model_layers_3_norm2_bias
x


input_45(
gamma

model_layers_3_norm2_weight
axes

input_47_axes_0&
input_47


≈
Ä*
name

"

input_47∫
linear
x


input_47'
bias

model_layers_3_mlp_fc1_bias+
weight!

model_layers_3_mlp_fc1_weight&
input_49


≈
Ä*
name

"
	linear_22c
const
input_51_mode_0
*%
name

"
input_51_mode_0*
val

	"
EXACT~
gelu
x


input_49
mode

input_51_mode_0&
input_51


≈
Ä*
name

"

input_51¡
linear
x


input_51'
bias

model_layers_3_mlp_fc2_bias+
weight!

model_layers_3_mlp_fc2_weight-
hidden_state_15


≈
Ä*
name

"
	linear_23°
mul
x

hidden_state_15,
y'
%
#model_layers_3_layer_scale2_lambda1,
layer_output_7


≈
Ä*$
name

"
layer_output_7y
add
x

layer_output_7
y


input_45&
input_53


≈
Ä*
name

"

input_53Ü
const&
hidden_states_9_axes_0


*,
name$

"
hidden_states_9_axes_0*'
val 





ˇˇˇˇˇˇˇˇˇÅ

layer_norm
epsilon


var_10%
beta

model_layers_4_norm1_bias
x


input_53(
gamma

model_layers_4_norm1_weight"
axes

hidden_states_9_axes_0-
hidden_states_9


≈
Ä*%
name

"
hidden_states_9‘
linear
x

hidden_states_90
bias(
&
$model_layers_4_attention_q_proj_bias4
weight*
(
&model_layers_4_attention_q_proj_weight'
	queries_9


≈
Ä*
name

"
	linear_24—
linear
x

hidden_states_90
bias(
&
$model_layers_4_attention_k_proj_bias4
weight*
(
&model_layers_4_attention_k_proj_weight$
keys_9


≈
Ä*
name

"
	linear_25”
linear
x

hidden_states_90
bias(
&
$model_layers_4_attention_v_proj_bias4
weight*
(
&model_layers_4_attention_v_proj_weight&
values_9


≈
Ä*
name

"
	linear_26b
const
var_361


*
name


"
op_361*"
val



	
≈@}
reshape
x

	queries_9
shape
	
var_361*
var_362


≈

@*
name


"
op_362b
const
var_364


*
name


"
op_364*"
val



	
≈@z
reshape
x


keys_9
shape
	
var_364*
var_365


≈

@*
name


"
op_365b
const
var_367


*
name


"
op_367*"
val



	
≈@|
reshape
x


values_9
shape
	
var_367*
var_368


≈

@*
name


"
op_368p
const
value_9_perm_0


*$
name

"
value_9_perm_0*!
val





 o
mul
x
	
var_362
y


var_12(
mul_4


≈

@*
name

	"
mul_4m
const
matmul_4_transpose_y_0
*,
name$

"
matmul_4_transpose_y_0*
val


m
const
matmul_4_transpose_x_0
*,
name$

"
matmul_4_transpose_x_0*
val


 å
const#
transpose_58_perm_0


*)
name!

"
transpose_58_perm_0*3
val,




 ˝ˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇå
const#
transpose_59_perm_0


*)
name!

"
transpose_59_perm_0*3
val,




 ˝ˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇî
	transpose
perm

transpose_59_perm_0
x
	
var_365/
transpose_59



≈
@*#
name

"
transpose_109í
	transpose
perm

transpose_58_perm_0
x	

mul_4/
transpose_58



≈
@*#
name

"
transpose_110⁄
matmul)
transpose_y

matmul_4_transpose_y_0
x

transpose_58
y

transpose_59)
transpose_x

matmul_4_transpose_x_0,
matmul_4 



≈
≈*
name

"

matmul_4j
const
softmax_4_axis_0
*&
name

"
softmax_4_axis_0*
val



ˇˇˇˇˇˇˇˇˇä
softmax
axis

softmax_4_axis_0
x


matmul_4-
	softmax_4 



≈
≈*
name

"
	softmax_4y
const$
attn_output_17_transpose_x_0
*2
name*
"
 "
attn_output_17_transpose_x_0*
val


 y
const$
attn_output_17_transpose_y_0
*2
name*
"
 "
attn_output_17_transpose_y_0*
val


 ä
	transpose
perm

value_9_perm_0
x
	
var_368*
value_9



≈
@*#
name

"
transpose_111È
matmul/
transpose_y 

attn_output_17_transpose_y_0
x

	softmax_4
y
	
value_9/
transpose_x 

attn_output_17_transpose_x_01
attn_output_17



≈
@*$
name

"
attn_output_17o
const
var_371_perm_0


*#
name

"
op_371_perm_0*!
val





 b
const
var_373


*
name


"
op_373*"
val



	
≈Äë
	transpose
perm

var_371_perm_0
x

attn_output_17*
var_371


≈

@*#
name

"
transpose_108v
reshape
x
	
var_371
shape
	
var_373%
var_374


≈
Ä*
name


"
op_374÷
linear
x
	
var_3742
bias*
(
&model_layers_4_attention_out_proj_bias6
weight,
*
(model_layers_4_attention_out_proj_weight-
hidden_state_17


≈
Ä*
name

"
	linear_27≥
mul
x

hidden_state_17,
y'
%
#model_layers_4_layer_scale1_lambda15
self_attention_output_9


≈
Ä*-
name%

"
self_attention_output_9Ç
add 
x

self_attention_output_9
y


input_53&
input_57


≈
Ä*
name

"

input_57x
const
input_59_axes_0


*%
name

"
input_59_axes_0*'
val 





ˇˇˇˇˇˇˇˇˇÏ

layer_norm
epsilon


var_10%
beta

model_layers_4_norm2_bias
x


input_57(
gamma

model_layers_4_norm2_weight
axes

input_59_axes_0&
input_59


≈
Ä*
name

"

input_59∫
linear
x


input_59'
bias

model_layers_4_mlp_fc1_bias+
weight!

model_layers_4_mlp_fc1_weight&
input_61


≈
Ä*
name

"
	linear_28c
const
input_63_mode_0
*%
name

"
input_63_mode_0*
val

	"
EXACT~
gelu
x


input_61
mode

input_63_mode_0&
input_63


≈
Ä*
name

"

input_63¡
linear
x


input_63'
bias

model_layers_4_mlp_fc2_bias+
weight!

model_layers_4_mlp_fc2_weight-
hidden_state_19


≈
Ä*
name

"
	linear_29°
mul
x

hidden_state_19,
y'
%
#model_layers_4_layer_scale2_lambda1,
layer_output_9


≈
Ä*$
name

"
layer_output_9y
add
x

layer_output_9
y


input_57&
input_65


≈
Ä*
name

"

input_65à
const'
hidden_states_11_axes_0


*-
name%

"
hidden_states_11_axes_0*'
val 





ˇˇˇˇˇˇˇˇˇÑ

layer_norm
epsilon


var_10%
beta

model_layers_5_norm1_bias
x


input_65(
gamma

model_layers_5_norm1_weight#
axes

hidden_states_11_axes_0.
hidden_states_11


≈
Ä*&
name

"
hidden_states_11÷
linear
x

hidden_states_110
bias(
&
$model_layers_5_attention_q_proj_bias4
weight*
(
&model_layers_5_attention_q_proj_weight(

queries_11


≈
Ä*
name

"
	linear_30”
linear
x

hidden_states_110
bias(
&
$model_layers_5_attention_k_proj_bias4
weight*
(
&model_layers_5_attention_k_proj_weight%
keys_11


≈
Ä*
name

"
	linear_31’
linear
x

hidden_states_110
bias(
&
$model_layers_5_attention_v_proj_bias4
weight*
(
&model_layers_5_attention_v_proj_weight'
	values_11


≈
Ä*
name

"
	linear_32b
const
var_424


*
name


"
op_424*"
val



	
≈@~
reshape
x


queries_11
shape
	
var_424*
var_425


≈

@*
name


"
op_425b
const
var_427


*
name


"
op_427*"
val



	
≈@{
reshape
x
	
keys_11
shape
	
var_427*
var_428


≈

@*
name


"
op_428b
const
var_430


*
name


"
op_430*"
val



	
≈@}
reshape
x

	values_11
shape
	
var_430*
var_431


≈

@*
name


"
op_431r
const
value_11_perm_0


*%
name

"
value_11_perm_0*!
val





 o
mul
x
	
var_425
y


var_12(
mul_5


≈

@*
name

	"
mul_5m
const
matmul_5_transpose_y_0
*,
name$

"
matmul_5_transpose_y_0*
val


m
const
matmul_5_transpose_x_0
*,
name$

"
matmul_5_transpose_x_0*
val


 å
const#
transpose_60_perm_0


*)
name!

"
transpose_60_perm_0*3
val,




 ˝ˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇå
const#
transpose_61_perm_0


*)
name!

"
transpose_61_perm_0*3
val,




 ˝ˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇî
	transpose
perm

transpose_61_perm_0
x
	
var_428/
transpose_61



≈
@*#
name

"
transpose_105í
	transpose
perm

transpose_60_perm_0
x	

mul_5/
transpose_60



≈
@*#
name

"
transpose_106⁄
matmul)
transpose_y

matmul_5_transpose_y_0
x

transpose_60
y

transpose_61)
transpose_x

matmul_5_transpose_x_0,
matmul_5 



≈
≈*
name

"

matmul_5j
const
softmax_5_axis_0
*&
name

"
softmax_5_axis_0*
val



ˇˇˇˇˇˇˇˇˇä
softmax
axis

softmax_5_axis_0
x


matmul_5-
	softmax_5 



≈
≈*
name

"
	softmax_5y
const$
attn_output_21_transpose_x_0
*2
name*
"
 "
attn_output_21_transpose_x_0*
val


 y
const$
attn_output_21_transpose_y_0
*2
name*
"
 "
attn_output_21_transpose_y_0*
val


 å
	transpose
perm

value_11_perm_0
x
	
var_431+
value_11



≈
@*#
name

"
transpose_107Í
matmul/
transpose_y 

attn_output_21_transpose_y_0
x

	softmax_5
y


value_11/
transpose_x 

attn_output_21_transpose_x_01
attn_output_21



≈
@*$
name

"
attn_output_21o
const
var_434_perm_0


*#
name

"
op_434_perm_0*!
val





 b
const
var_436


*
name


"
op_436*"
val



	
≈Äë
	transpose
perm

var_434_perm_0
x

attn_output_21*
var_434


≈

@*#
name

"
transpose_104v
reshape
x
	
var_434
shape
	
var_436%
var_437


≈
Ä*
name


"
op_437÷
linear
x
	
var_4372
bias*
(
&model_layers_5_attention_out_proj_bias6
weight,
*
(model_layers_5_attention_out_proj_weight-
hidden_state_21


≈
Ä*
name

"
	linear_33µ
mul
x

hidden_state_21,
y'
%
#model_layers_5_layer_scale1_lambda16
self_attention_output_11


≈
Ä*.
name&

"
self_attention_output_11É
add!
x

self_attention_output_11
y


input_65&
input_69


≈
Ä*
name

"

input_69x
const
input_71_axes_0


*%
name

"
input_71_axes_0*'
val 





ˇˇˇˇˇˇˇˇˇÏ

layer_norm
epsilon


var_10%
beta

model_layers_5_norm2_bias
x


input_69(
gamma

model_layers_5_norm2_weight
axes

input_71_axes_0&
input_71


≈
Ä*
name

"

input_71∫
linear
x


input_71'
bias

model_layers_5_mlp_fc1_bias+
weight!

model_layers_5_mlp_fc1_weight&
input_73


≈
Ä*
name

"
	linear_34c
const
input_75_mode_0
*%
name

"
input_75_mode_0*
val

	"
EXACT~
gelu
x


input_73
mode

input_75_mode_0&
input_75


≈
Ä*
name

"

input_75¡
linear
x


input_75'
bias

model_layers_5_mlp_fc2_bias+
weight!

model_layers_5_mlp_fc2_weight-
hidden_state_23


≈
Ä*
name

"
	linear_35£
mul
x

hidden_state_23,
y'
%
#model_layers_5_layer_scale2_lambda1-
layer_output_11


≈
Ä*%
name

"
layer_output_11z
add
x

layer_output_11
y


input_69&
input_77


≈
Ä*
name

"

input_77à
const'
hidden_states_13_axes_0


*-
name%

"
hidden_states_13_axes_0*'
val 





ˇˇˇˇˇˇˇˇˇÑ

layer_norm
epsilon


var_10%
beta

model_layers_6_norm1_bias
x


input_77(
gamma

model_layers_6_norm1_weight#
axes

hidden_states_13_axes_0.
hidden_states_13


≈
Ä*&
name

"
hidden_states_13÷
linear
x

hidden_states_130
bias(
&
$model_layers_6_attention_q_proj_bias4
weight*
(
&model_layers_6_attention_q_proj_weight(

queries_13


≈
Ä*
name

"
	linear_36”
linear
x

hidden_states_130
bias(
&
$model_layers_6_attention_k_proj_bias4
weight*
(
&model_layers_6_attention_k_proj_weight%
keys_13


≈
Ä*
name

"
	linear_37’
linear
x

hidden_states_130
bias(
&
$model_layers_6_attention_v_proj_bias4
weight*
(
&model_layers_6_attention_v_proj_weight'
	values_13


≈
Ä*
name

"
	linear_38b
const
var_487


*
name


"
op_487*"
val



	
≈@~
reshape
x


queries_13
shape
	
var_487*
var_488


≈

@*
name


"
op_488b
const
var_490


*
name


"
op_490*"
val



	
≈@{
reshape
x
	
keys_13
shape
	
var_490*
var_491


≈

@*
name


"
op_491b
const
var_493


*
name


"
op_493*"
val



	
≈@}
reshape
x

	values_13
shape
	
var_493*
var_494


≈

@*
name


"
op_494r
const
value_13_perm_0


*%
name

"
value_13_perm_0*!
val





 o
mul
x
	
var_488
y


var_12(
mul_6


≈

@*
name

	"
mul_6m
const
matmul_6_transpose_y_0
*,
name$

"
matmul_6_transpose_y_0*
val


m
const
matmul_6_transpose_x_0
*,
name$

"
matmul_6_transpose_x_0*
val


 å
const#
transpose_62_perm_0


*)
name!

"
transpose_62_perm_0*3
val,




 ˝ˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇå
const#
transpose_63_perm_0


*)
name!

"
transpose_63_perm_0*3
val,




 ˝ˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇî
	transpose
perm

transpose_63_perm_0
x
	
var_491/
transpose_63



≈
@*#
name

"
transpose_101í
	transpose
perm

transpose_62_perm_0
x	

mul_6/
transpose_62



≈
@*#
name

"
transpose_102⁄
matmul)
transpose_y

matmul_6_transpose_y_0
x

transpose_62
y

transpose_63)
transpose_x

matmul_6_transpose_x_0,
matmul_6 



≈
≈*
name

"

matmul_6j
const
softmax_6_axis_0
*&
name

"
softmax_6_axis_0*
val



ˇˇˇˇˇˇˇˇˇä
softmax
axis

softmax_6_axis_0
x


matmul_6-
	softmax_6 



≈
≈*
name

"
	softmax_6y
const$
attn_output_25_transpose_x_0
*2
name*
"
 "
attn_output_25_transpose_x_0*
val


 y
const$
attn_output_25_transpose_y_0
*2
name*
"
 "
attn_output_25_transpose_y_0*
val


 å
	transpose
perm

value_13_perm_0
x
	
var_494+
value_13



≈
@*#
name

"
transpose_103Í
matmul/
transpose_y 

attn_output_25_transpose_y_0
x

	softmax_6
y


value_13/
transpose_x 

attn_output_25_transpose_x_01
attn_output_25



≈
@*$
name

"
attn_output_25o
const
var_497_perm_0


*#
name

"
op_497_perm_0*!
val





 b
const
var_499


*
name


"
op_499*"
val



	
≈Äë
	transpose
perm

var_497_perm_0
x

attn_output_25*
var_497


≈

@*#
name

"
transpose_100v
reshape
x
	
var_497
shape
	
var_499%
var_500


≈
Ä*
name


"
op_500÷
linear
x
	
var_5002
bias*
(
&model_layers_6_attention_out_proj_bias6
weight,
*
(model_layers_6_attention_out_proj_weight-
hidden_state_25


≈
Ä*
name

"
	linear_39µ
mul
x

hidden_state_25,
y'
%
#model_layers_6_layer_scale1_lambda16
self_attention_output_13


≈
Ä*.
name&

"
self_attention_output_13É
add!
x

self_attention_output_13
y


input_77&
input_81


≈
Ä*
name

"

input_81x
const
input_83_axes_0


*%
name

"
input_83_axes_0*'
val 





ˇˇˇˇˇˇˇˇˇÏ

layer_norm
epsilon


var_10%
beta

model_layers_6_norm2_bias
x


input_81(
gamma

model_layers_6_norm2_weight
axes

input_83_axes_0&
input_83


≈
Ä*
name

"

input_83∫
linear
x


input_83'
bias

model_layers_6_mlp_fc1_bias+
weight!

model_layers_6_mlp_fc1_weight&
input_85


≈
Ä*
name

"
	linear_40c
const
input_87_mode_0
*%
name

"
input_87_mode_0*
val

	"
EXACT~
gelu
x


input_85
mode

input_87_mode_0&
input_87


≈
Ä*
name

"

input_87¡
linear
x


input_87'
bias

model_layers_6_mlp_fc2_bias+
weight!

model_layers_6_mlp_fc2_weight-
hidden_state_27


≈
Ä*
name

"
	linear_41£
mul
x

hidden_state_27,
y'
%
#model_layers_6_layer_scale2_lambda1-
layer_output_13


≈
Ä*%
name

"
layer_output_13z
add
x

layer_output_13
y


input_81&
input_89


≈
Ä*
name

"

input_89à
const'
hidden_states_15_axes_0


*-
name%

"
hidden_states_15_axes_0*'
val 





ˇˇˇˇˇˇˇˇˇÑ

layer_norm
epsilon


var_10%
beta

model_layers_7_norm1_bias
x


input_89(
gamma

model_layers_7_norm1_weight#
axes

hidden_states_15_axes_0.
hidden_states_15


≈
Ä*&
name

"
hidden_states_15÷
linear
x

hidden_states_150
bias(
&
$model_layers_7_attention_q_proj_bias4
weight*
(
&model_layers_7_attention_q_proj_weight(

queries_15


≈
Ä*
name

"
	linear_42”
linear
x

hidden_states_150
bias(
&
$model_layers_7_attention_k_proj_bias4
weight*
(
&model_layers_7_attention_k_proj_weight%
keys_15


≈
Ä*
name

"
	linear_43’
linear
x

hidden_states_150
bias(
&
$model_layers_7_attention_v_proj_bias4
weight*
(
&model_layers_7_attention_v_proj_weight'
	values_15


≈
Ä*
name

"
	linear_44b
const
var_550


*
name


"
op_550*"
val



	
≈@~
reshape
x


queries_15
shape
	
var_550*
var_551


≈

@*
name


"
op_551b
const
var_553


*
name


"
op_553*"
val



	
≈@{
reshape
x
	
keys_15
shape
	
var_553*
var_554


≈

@*
name


"
op_554b
const
var_556


*
name


"
op_556*"
val



	
≈@}
reshape
x

	values_15
shape
	
var_556*
var_557


≈

@*
name


"
op_557r
const
value_15_perm_0


*%
name

"
value_15_perm_0*!
val





 o
mul
x
	
var_551
y


var_12(
mul_7


≈

@*
name

	"
mul_7m
const
matmul_7_transpose_y_0
*,
name$

"
matmul_7_transpose_y_0*
val


m
const
matmul_7_transpose_x_0
*,
name$

"
matmul_7_transpose_x_0*
val


 å
const#
transpose_64_perm_0


*)
name!

"
transpose_64_perm_0*3
val,




 ˝ˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇå
const#
transpose_65_perm_0


*)
name!

"
transpose_65_perm_0*3
val,




 ˝ˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇì
	transpose
perm

transpose_65_perm_0
x
	
var_554/
transpose_65



≈
@*"
name

"
transpose_97ë
	transpose
perm

transpose_64_perm_0
x	

mul_7/
transpose_64



≈
@*"
name

"
transpose_98⁄
matmul)
transpose_y

matmul_7_transpose_y_0
x

transpose_64
y

transpose_65)
transpose_x

matmul_7_transpose_x_0,
matmul_7 



≈
≈*
name

"

matmul_7j
const
softmax_7_axis_0
*&
name

"
softmax_7_axis_0*
val



ˇˇˇˇˇˇˇˇˇä
softmax
axis

softmax_7_axis_0
x


matmul_7-
	softmax_7 



≈
≈*
name

"
	softmax_7y
const$
attn_output_29_transpose_x_0
*2
name*
"
 "
attn_output_29_transpose_x_0*
val


 y
const$
attn_output_29_transpose_y_0
*2
name*
"
 "
attn_output_29_transpose_y_0*
val


 ã
	transpose
perm

value_15_perm_0
x
	
var_557+
value_15



≈
@*"
name

"
transpose_99Í
matmul/
transpose_y 

attn_output_29_transpose_y_0
x

	softmax_7
y


value_15/
transpose_x 

attn_output_29_transpose_x_01
attn_output_29



≈
@*$
name

"
attn_output_29o
const
var_560_perm_0


*#
name

"
op_560_perm_0*!
val





 b
const
var_562


*
name


"
op_562*"
val



	
≈Äê
	transpose
perm

var_560_perm_0
x

attn_output_29*
var_560


≈

@*"
name

"
transpose_96v
reshape
x
	
var_560
shape
	
var_562%
var_563


≈
Ä*
name


"
op_563÷
linear
x
	
var_5632
bias*
(
&model_layers_7_attention_out_proj_bias6
weight,
*
(model_layers_7_attention_out_proj_weight-
hidden_state_29


≈
Ä*
name

"
	linear_45µ
mul
x

hidden_state_29,
y'
%
#model_layers_7_layer_scale1_lambda16
self_attention_output_15


≈
Ä*.
name&

"
self_attention_output_15É
add!
x

self_attention_output_15
y


input_89&
input_93


≈
Ä*
name

"

input_93x
const
input_95_axes_0


*%
name

"
input_95_axes_0*'
val 





ˇˇˇˇˇˇˇˇˇÏ

layer_norm
epsilon


var_10%
beta

model_layers_7_norm2_bias
x


input_93(
gamma

model_layers_7_norm2_weight
axes

input_95_axes_0&
input_95


≈
Ä*
name

"

input_95∫
linear
x


input_95'
bias

model_layers_7_mlp_fc1_bias+
weight!

model_layers_7_mlp_fc1_weight&
input_97


≈
Ä*
name

"
	linear_46c
const
input_99_mode_0
*%
name

"
input_99_mode_0*
val

	"
EXACT~
gelu
x


input_97
mode

input_99_mode_0&
input_99


≈
Ä*
name

"

input_99¡
linear
x


input_99'
bias

model_layers_7_mlp_fc2_bias+
weight!

model_layers_7_mlp_fc2_weight-
hidden_state_31


≈
Ä*
name

"
	linear_47£
mul
x

hidden_state_31,
y'
%
#model_layers_7_layer_scale2_lambda1-
layer_output_15


≈
Ä*%
name

"
layer_output_15|
add
x

layer_output_15
y


input_93'
	input_101


≈
Ä*
name

"
	input_101à
const'
hidden_states_17_axes_0


*-
name%

"
hidden_states_17_axes_0*'
val 





ˇˇˇˇˇˇˇˇˇÖ

layer_norm
epsilon


var_10%
beta

model_layers_8_norm1_bias
x

	input_101(
gamma

model_layers_8_norm1_weight#
axes

hidden_states_17_axes_0.
hidden_states_17


≈
Ä*&
name

"
hidden_states_17÷
linear
x

hidden_states_170
bias(
&
$model_layers_8_attention_q_proj_bias4
weight*
(
&model_layers_8_attention_q_proj_weight(

queries_17


≈
Ä*
name

"
	linear_48”
linear
x

hidden_states_170
bias(
&
$model_layers_8_attention_k_proj_bias4
weight*
(
&model_layers_8_attention_k_proj_weight%
keys_17


≈
Ä*
name

"
	linear_49’
linear
x

hidden_states_170
bias(
&
$model_layers_8_attention_v_proj_bias4
weight*
(
&model_layers_8_attention_v_proj_weight'
	values_17


≈
Ä*
name

"
	linear_50b
const
var_613


*
name


"
op_613*"
val



	
≈@~
reshape
x


queries_17
shape
	
var_613*
var_614


≈

@*
name


"
op_614b
const
var_616


*
name


"
op_616*"
val



	
≈@{
reshape
x
	
keys_17
shape
	
var_616*
var_617


≈

@*
name


"
op_617b
const
var_619


*
name


"
op_619*"
val



	
≈@}
reshape
x

	values_17
shape
	
var_619*
var_620


≈

@*
name


"
op_620r
const
value_17_perm_0


*%
name

"
value_17_perm_0*!
val





 o
mul
x
	
var_614
y


var_12(
mul_8


≈

@*
name

	"
mul_8m
const
matmul_8_transpose_y_0
*,
name$

"
matmul_8_transpose_y_0*
val


m
const
matmul_8_transpose_x_0
*,
name$

"
matmul_8_transpose_x_0*
val


 å
const#
transpose_66_perm_0


*)
name!

"
transpose_66_perm_0*3
val,




 ˝ˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇå
const#
transpose_67_perm_0


*)
name!

"
transpose_67_perm_0*3
val,




 ˝ˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇì
	transpose
perm

transpose_67_perm_0
x
	
var_617/
transpose_67



≈
@*"
name

"
transpose_93ë
	transpose
perm

transpose_66_perm_0
x	

mul_8/
transpose_66



≈
@*"
name

"
transpose_94⁄
matmul)
transpose_y

matmul_8_transpose_y_0
x

transpose_66
y

transpose_67)
transpose_x

matmul_8_transpose_x_0,
matmul_8 



≈
≈*
name

"

matmul_8j
const
softmax_8_axis_0
*&
name

"
softmax_8_axis_0*
val



ˇˇˇˇˇˇˇˇˇä
softmax
axis

softmax_8_axis_0
x


matmul_8-
	softmax_8 



≈
≈*
name

"
	softmax_8y
const$
attn_output_33_transpose_x_0
*2
name*
"
 "
attn_output_33_transpose_x_0*
val


 y
const$
attn_output_33_transpose_y_0
*2
name*
"
 "
attn_output_33_transpose_y_0*
val


 ã
	transpose
perm

value_17_perm_0
x
	
var_620+
value_17



≈
@*"
name

"
transpose_95Í
matmul/
transpose_y 

attn_output_33_transpose_y_0
x

	softmax_8
y


value_17/
transpose_x 

attn_output_33_transpose_x_01
attn_output_33



≈
@*$
name

"
attn_output_33o
const
var_623_perm_0


*#
name

"
op_623_perm_0*!
val





 b
const
var_625


*
name


"
op_625*"
val



	
≈Äê
	transpose
perm

var_623_perm_0
x

attn_output_33*
var_623


≈

@*"
name

"
transpose_92v
reshape
x
	
var_623
shape
	
var_625%
var_626


≈
Ä*
name


"
op_626÷
linear
x
	
var_6262
bias*
(
&model_layers_8_attention_out_proj_bias6
weight,
*
(model_layers_8_attention_out_proj_weight-
hidden_state_33


≈
Ä*
name

"
	linear_51µ
mul
x

hidden_state_33,
y'
%
#model_layers_8_layer_scale1_lambda16
self_attention_output_17


≈
Ä*.
name&

"
self_attention_output_17Ü
add!
x

self_attention_output_17
y

	input_101'
	input_105


≈
Ä*
name

"
	input_105z
const 
input_107_axes_0


*&
name

"
input_107_axes_0*'
val 





ˇˇˇˇˇˇˇˇˇ

layer_norm
epsilon


var_10%
beta

model_layers_8_norm2_bias
x

	input_105(
gamma

model_layers_8_norm2_weight
axes

input_107_axes_0'
	input_107


≈
Ä*
name

"
	input_107º
linear
x

	input_107'
bias

model_layers_8_mlp_fc1_bias+
weight!

model_layers_8_mlp_fc1_weight'
	input_109


≈
Ä*
name

"
	linear_52e
const
input_111_mode_0
*&
name

"
input_111_mode_0*
val

	"
EXACTÇ
gelu
x

	input_109
mode

input_111_mode_0'
	input_111


≈
Ä*
name

"
	input_111¬
linear
x

	input_111'
bias

model_layers_8_mlp_fc2_bias+
weight!

model_layers_8_mlp_fc2_weight-
hidden_state_35


≈
Ä*
name

"
	linear_53£
mul
x

hidden_state_35,
y'
%
#model_layers_8_layer_scale2_lambda1-
layer_output_17


≈
Ä*%
name

"
layer_output_17ã
add
x

layer_output_17
y

	input_105.
hidden_states_19


≈
Ä*&
name

"
hidden_states_19õ
const&
const_29


»
Ä*
name

"

const_29*J
valC


»
Ä*%
@model_path/weights/weight.bin¿ŸÀ-m
const
input_113_interleave_0
*,
name$

"
input_113_interleave_0*
val


 º
concat
axis


var_22(

interleave

input_113_interleave_0*
values 


const_29

hidden_states_19'
	input_113


ç
Ä*
name

"
	input_113à
const'
hidden_states_21_axes_0


*-
name%

"
hidden_states_21_axes_0*'
val 





ˇˇˇˇˇˇˇˇˇÖ

layer_norm
epsilon


var_10%
beta

model_layers_9_norm1_bias
x

	input_113(
gamma

model_layers_9_norm1_weight#
axes

hidden_states_21_axes_0.
hidden_states_21


ç
Ä*&
name

"
hidden_states_21÷
linear
x

hidden_states_210
bias(
&
$model_layers_9_attention_q_proj_bias4
weight*
(
&model_layers_9_attention_q_proj_weight(

queries_19


ç
Ä*
name

"
	linear_54”
linear
x

hidden_states_210
bias(
&
$model_layers_9_attention_k_proj_bias4
weight*
(
&model_layers_9_attention_k_proj_weight%
keys_19


ç
Ä*
name

"
	linear_55’
linear
x

hidden_states_210
bias(
&
$model_layers_9_attention_v_proj_bias4
weight*
(
&model_layers_9_attention_v_proj_weight'
	values_19


ç
Ä*
name

"
	linear_56b
const
var_685


*
name


"
op_685*"
val



	
ç@~
reshape
x


queries_19
shape
	
var_685*
var_686


ç

@*
name


"
op_686b
const
var_688


*
name


"
op_688*"
val



	
ç@{
reshape
x
	
keys_19
shape
	
var_688*
var_689


ç

@*
name


"
op_689b
const
var_691


*
name


"
op_691*"
val



	
ç@}
reshape
x

	values_19
shape
	
var_691*
var_692


ç

@*
name


"
op_692r
const
value_19_perm_0


*%
name

"
value_19_perm_0*!
val





 o
mul
x
	
var_686
y


var_12(
mul_9


ç

@*
name

	"
mul_9m
const
matmul_9_transpose_y_0
*,
name$

"
matmul_9_transpose_y_0*
val


m
const
matmul_9_transpose_x_0
*,
name$

"
matmul_9_transpose_x_0*
val


 å
const#
transpose_68_perm_0


*)
name!

"
transpose_68_perm_0*3
val,




 ˝ˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇå
const#
transpose_69_perm_0


*)
name!

"
transpose_69_perm_0*3
val,




 ˝ˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇì
	transpose
perm

transpose_69_perm_0
x
	
var_689/
transpose_69



ç
@*"
name

"
transpose_89ë
	transpose
perm

transpose_68_perm_0
x	

mul_9/
transpose_68



ç
@*"
name

"
transpose_90⁄
matmul)
transpose_y

matmul_9_transpose_y_0
x

transpose_68
y

transpose_69)
transpose_x

matmul_9_transpose_x_0,
matmul_9 



ç
ç*
name

"

matmul_9j
const
softmax_9_axis_0
*&
name

"
softmax_9_axis_0*
val



ˇˇˇˇˇˇˇˇˇä
softmax
axis

softmax_9_axis_0
x


matmul_9-
	softmax_9 



ç
ç*
name

"
	softmax_9y
const$
attn_output_37_transpose_x_0
*2
name*
"
 "
attn_output_37_transpose_x_0*
val


 y
const$
attn_output_37_transpose_y_0
*2
name*
"
 "
attn_output_37_transpose_y_0*
val


 ã
	transpose
perm

value_19_perm_0
x
	
var_692+
value_19



ç
@*"
name

"
transpose_91Í
matmul/
transpose_y 

attn_output_37_transpose_y_0
x

	softmax_9
y


value_19/
transpose_x 

attn_output_37_transpose_x_01
attn_output_37



ç
@*$
name

"
attn_output_37o
const
var_695_perm_0


*#
name

"
op_695_perm_0*!
val





 b
const
var_697


*
name


"
op_697*"
val



	
çÄê
	transpose
perm

var_695_perm_0
x

attn_output_37*
var_695


ç

@*"
name

"
transpose_88v
reshape
x
	
var_695
shape
	
var_697%
var_698


ç
Ä*
name


"
op_698÷
linear
x
	
var_6982
bias*
(
&model_layers_9_attention_out_proj_bias6
weight,
*
(model_layers_9_attention_out_proj_weight-
hidden_state_37


ç
Ä*
name

"
	linear_57µ
mul
x

hidden_state_37,
y'
%
#model_layers_9_layer_scale1_lambda16
self_attention_output_19


ç
Ä*.
name&

"
self_attention_output_19Ü
add!
x

self_attention_output_19
y

	input_113'
	input_117


ç
Ä*
name

"
	input_117z
const 
input_119_axes_0


*&
name

"
input_119_axes_0*'
val 





ˇˇˇˇˇˇˇˇˇ

layer_norm
epsilon


var_10%
beta

model_layers_9_norm2_bias
x

	input_117(
gamma

model_layers_9_norm2_weight
axes

input_119_axes_0'
	input_119


ç
Ä*
name

"
	input_119º
linear
x

	input_119'
bias

model_layers_9_mlp_fc1_bias+
weight!

model_layers_9_mlp_fc1_weight'
	input_121


ç
Ä*
name

"
	linear_58e
const
input_123_mode_0
*&
name

"
input_123_mode_0*
val

	"
EXACTÇ
gelu
x

	input_121
mode

input_123_mode_0'
	input_123


ç
Ä*
name

"
	input_123¬
linear
x

	input_123'
bias

model_layers_9_mlp_fc2_bias+
weight!

model_layers_9_mlp_fc2_weight-
hidden_state_39


ç
Ä*
name

"
	linear_59£
mul
x

hidden_state_39,
y'
%
#model_layers_9_layer_scale2_lambda1-
layer_output_19


ç
Ä*%
name

"
layer_output_19}
add
x

layer_output_19
y

	input_117'
	input_125


ç
Ä*
name

"
	input_125à
const'
hidden_states_23_axes_0


*-
name%

"
hidden_states_23_axes_0*'
val 





ˇˇˇˇˇˇˇˇˇá

layer_norm
epsilon


var_10&
beta

model_layers_10_norm1_bias
x

	input_125)
gamma 

model_layers_10_norm1_weight#
axes

hidden_states_23_axes_0.
hidden_states_23


ç
Ä*&
name

"
hidden_states_23ÿ
linear
x

hidden_states_231
bias)
'
%model_layers_10_attention_q_proj_bias5
weight+
)
'model_layers_10_attention_q_proj_weight(

queries_21


ç
Ä*
name

"
	linear_60’
linear
x

hidden_states_231
bias)
'
%model_layers_10_attention_k_proj_bias5
weight+
)
'model_layers_10_attention_k_proj_weight%
keys_21


ç
Ä*
name

"
	linear_61◊
linear
x

hidden_states_231
bias)
'
%model_layers_10_attention_v_proj_bias5
weight+
)
'model_layers_10_attention_v_proj_weight'
	values_21


ç
Ä*
name

"
	linear_62b
const
var_748


*
name


"
op_748*"
val



	
ç@~
reshape
x


queries_21
shape
	
var_748*
var_749


ç

@*
name


"
op_749b
const
var_751


*
name


"
op_751*"
val



	
ç@{
reshape
x
	
keys_21
shape
	
var_751*
var_752


ç

@*
name


"
op_752b
const
var_754


*
name


"
op_754*"
val



	
ç@}
reshape
x

	values_21
shape
	
var_754*
var_755


ç

@*
name


"
op_755r
const
value_21_perm_0


*%
name

"
value_21_perm_0*!
val





 q
mul
x
	
var_749
y


var_12)
mul_10


ç

@*
name


"
mul_10o
const
matmul_10_transpose_y_0
*-
name%

"
matmul_10_transpose_y_0*
val


o
const
matmul_10_transpose_x_0
*-
name%

"
matmul_10_transpose_x_0*
val


 å
const#
transpose_70_perm_0


*)
name!

"
transpose_70_perm_0*3
val,




 ˝ˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇå
const#
transpose_71_perm_0


*)
name!

"
transpose_71_perm_0*3
val,




 ˝ˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇì
	transpose
perm

transpose_71_perm_0
x
	
var_752/
transpose_71



ç
@*"
name

"
transpose_85í
	transpose
perm

transpose_70_perm_0
x


mul_10/
transpose_70



ç
@*"
name

"
transpose_86ﬁ
matmul*
transpose_y

matmul_10_transpose_y_0
x

transpose_70
y

transpose_71*
transpose_x

matmul_10_transpose_x_0-
	matmul_10 



ç
ç*
name

"
	matmul_10l
const
softmax_10_axis_0
*'
name

"
softmax_10_axis_0*
val



ˇˇˇˇˇˇˇˇˇé
softmax
axis

softmax_10_axis_0
x

	matmul_10.

softmax_10 



ç
ç* 
name

"

softmax_10y
const$
attn_output_41_transpose_x_0
*2
name*
"
 "
attn_output_41_transpose_x_0*
val


 y
const$
attn_output_41_transpose_y_0
*2
name*
"
 "
attn_output_41_transpose_y_0*
val


 ã
	transpose
perm

value_21_perm_0
x
	
var_755+
value_21



ç
@*"
name

"
transpose_87Î
matmul/
transpose_y 

attn_output_41_transpose_y_0
x


softmax_10
y


value_21/
transpose_x 

attn_output_41_transpose_x_01
attn_output_41



ç
@*$
name

"
attn_output_41o
const
var_758_perm_0


*#
name

"
op_758_perm_0*!
val





 b
const
var_760


*
name


"
op_760*"
val



	
çÄê
	transpose
perm

var_758_perm_0
x

attn_output_41*
var_758


ç

@*"
name

"
transpose_84v
reshape
x
	
var_758
shape
	
var_760%
var_761


ç
Ä*
name


"
op_761ÿ
linear
x
	
var_7613
bias+
)
'model_layers_10_attention_out_proj_bias7
weight-
+
)model_layers_10_attention_out_proj_weight-
hidden_state_41


ç
Ä*
name

"
	linear_63∂
mul
x

hidden_state_41-
y(
&
$model_layers_10_layer_scale1_lambda16
self_attention_output_21


ç
Ä*.
name&

"
self_attention_output_21Ü
add!
x

self_attention_output_21
y

	input_125'
	input_129


ç
Ä*
name

"
	input_129z
const 
input_131_axes_0


*&
name

"
input_131_axes_0*'
val 





ˇˇˇˇˇˇˇˇˇÚ

layer_norm
epsilon


var_10&
beta

model_layers_10_norm2_bias
x

	input_129)
gamma 

model_layers_10_norm2_weight
axes

input_131_axes_0'
	input_131


ç
Ä*
name

"
	input_131æ
linear
x

	input_131(
bias 

model_layers_10_mlp_fc1_bias,
weight"
 
model_layers_10_mlp_fc1_weight'
	input_133


ç
Ä*
name

"
	linear_64e
const
input_135_mode_0
*&
name

"
input_135_mode_0*
val

	"
EXACTÇ
gelu
x

	input_133
mode

input_135_mode_0'
	input_135


ç
Ä*
name

"
	input_135ƒ
linear
x

	input_135(
bias 

model_layers_10_mlp_fc2_bias,
weight"
 
model_layers_10_mlp_fc2_weight-
hidden_state_43


ç
Ä*
name

"
	linear_65§
mul
x

hidden_state_43-
y(
&
$model_layers_10_layer_scale2_lambda1-
layer_output_21


ç
Ä*%
name

"
layer_output_21}
add
x

layer_output_21
y

	input_129'
	input_137


ç
Ä*
name

"
	input_137Ç
const$
hidden_states_axes_0


**
name"

"
hidden_states_axes_0*'
val 





ˇˇˇˇˇˇˇˇˇ˛

layer_norm
epsilon


var_10&
beta

model_layers_11_norm1_bias
x

	input_137)
gamma 

model_layers_11_norm1_weight 
axes

hidden_states_axes_0+
hidden_states


ç
Ä*#
name

"
hidden_states“
linear
x

hidden_states1
bias)
'
%model_layers_11_attention_q_proj_bias5
weight+
)
'model_layers_11_attention_q_proj_weight%
queries


ç
Ä*
name

"
	linear_66œ
linear
x

hidden_states1
bias)
'
%model_layers_11_attention_k_proj_bias5
weight+
)
'model_layers_11_attention_k_proj_weight"
keys


ç
Ä*
name

"
	linear_67—
linear
x

hidden_states1
bias)
'
%model_layers_11_attention_v_proj_bias5
weight+
)
'model_layers_11_attention_v_proj_weight$
values


ç
Ä*
name

"
	linear_68b
const
var_811


*
name


"
op_811*"
val



	
ç@{
reshape
x
	
queries
shape
	
var_811*
var_812


ç

@*
name


"
op_812b
const
var_814


*
name


"
op_814*"
val



	
ç@x
reshape
x

keys
shape
	
var_814*
var_815


ç

@*
name


"
op_815b
const
var_817


*
name


"
op_817*"
val



	
ç@z
reshape
x


values
shape
	
var_817*
var_818


ç

@*
name


"
op_818l
const
value_perm_0


*"
name

"
value_perm_0*!
val





 q
mul
x
	
var_812
y


var_12)
mul_11


ç

@*
name


"
mul_11o
const
matmul_11_transpose_y_0
*-
name%

"
matmul_11_transpose_y_0*
val


o
const
matmul_11_transpose_x_0
*-
name%

"
matmul_11_transpose_x_0*
val


 å
const#
transpose_72_perm_0


*)
name!

"
transpose_72_perm_0*3
val,




 ˝ˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇå
const#
transpose_73_perm_0


*)
name!

"
transpose_73_perm_0*3
val,




 ˝ˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇˇì
	transpose
perm

transpose_73_perm_0
x
	
var_815/
transpose_73



ç
@*"
name

"
transpose_81í
	transpose
perm

transpose_72_perm_0
x


mul_11/
transpose_72



ç
@*"
name

"
transpose_82ﬁ
matmul*
transpose_y

matmul_11_transpose_y_0
x

transpose_72
y

transpose_73*
transpose_x

matmul_11_transpose_x_0-
	matmul_11 



ç
ç*
name

"
	matmul_11l
const
softmax_11_axis_0
*'
name

"
softmax_11_axis_0*
val



ˇˇˇˇˇˇˇˇˇé
softmax
axis

softmax_11_axis_0
x

	matmul_11.

softmax_11 



ç
ç* 
name

"

softmax_11y
const$
attn_output_45_transpose_x_0
*2
name*
"
 "
attn_output_45_transpose_x_0*
val


 y
const$
attn_output_45_transpose_y_0
*2
name*
"
 "
attn_output_45_transpose_y_0*
val


 Ö
	transpose
perm

value_perm_0
x
	
var_818(
value



ç
@*"
name

"
transpose_83Ë
matmul/
transpose_y 

attn_output_45_transpose_y_0
x


softmax_11
y	

value/
transpose_x 

attn_output_45_transpose_x_01
attn_output_45



ç
@*$
name

"
attn_output_45o
const
var_821_perm_0


*#
name

"
op_821_perm_0*!
val





 b
const
var_823


*
name


"
op_823*"
val



	
çÄê
	transpose
perm

var_821_perm_0
x

attn_output_45*
var_821


ç

@*"
name

"
transpose_80v
reshape
x
	
var_821
shape
	
var_823%
var_824


ç
Ä*
name


"
op_824ÿ
linear
x
	
var_8243
bias+
)
'model_layers_11_attention_out_proj_bias7
weight-
+
)model_layers_11_attention_out_proj_weight-
hidden_state_45


ç
Ä*
name

"
	linear_69∞
mul
x

hidden_state_45-
y(
&
$model_layers_11_layer_scale1_lambda13
self_attention_output


ç
Ä*+
name#

"
self_attention_outputÉ
add
x

self_attention_output
y

	input_137'
	input_141


ç
Ä*
name

"
	input_141z
const 
input_143_axes_0


*&
name

"
input_143_axes_0*'
val 





ˇˇˇˇˇˇˇˇˇÚ

layer_norm
epsilon


var_10&
beta

model_layers_11_norm2_bias
x

	input_141)
gamma 

model_layers_11_norm2_weight
axes

input_143_axes_0'
	input_143


ç
Ä*
name

"
	input_143æ
linear
x

	input_143(
bias 

model_layers_11_mlp_fc1_bias,
weight"
 
model_layers_11_mlp_fc1_weight'
	input_145


ç
Ä*
name

"
	linear_70e
const
input_147_mode_0
*&
name

"
input_147_mode_0*
val

	"
EXACTÇ
gelu
x

	input_145
mode

input_147_mode_0'
	input_147


ç
Ä*
name

"
	input_147ƒ
linear
x

	input_147(
bias 

model_layers_11_mlp_fc2_bias,
weight"
 
model_layers_11_mlp_fc2_weight-
hidden_state_47


ç
Ä*
name

"
	linear_71û
mul
x

hidden_state_47-
y(
&
$model_layers_11_layer_scale2_lambda1*
layer_output


ç
Ä*"
name

"
layer_outputz
add
x

layer_output
y

	input_141'
	input_149


ç
Ä*
name

"
	input_149t
const
logits_axes_0


*#
name

"
logits_axes_0*'
val 





ˇˇˇˇˇˇˇˇˇ›

layer_norm
epsilon


var_10 
beta

model_layernorm_bias
x

	input_149#
gamma

model_layernorm_weight
axes

logits_axes_0$
logits


ç
Ä*
name


"
logitsp
const
var_853_begin_0


*$
name

"
op_853_begin_0* 
val


	

   n
const
var_853_end_0


*"
name

"
op_853_end_0*"
val



	
»Äv
const"
var_853_end_mask_0


*'
name

"
op_853_end_mask_0* 
val


	

 ¬
slice_by_index
begin

var_853_begin_0
x


logits"
end_mask

var_853_end_mask_0
end

var_853_end_0%
var_853


»
Ä*
name


"
op_853ª
linear
x
	
var_853&
bias

model_class_predictor_bias*
weight 

model_class_predictor_weight*
class_logits


»
Ü*
name

"
	linear_72q
const
var_859_begin_0


*$
name

"
op_859_begin_0*!
val





 Õ n
const
var_859_end_0


*"
name

"
op_859_end_0*"
val



	
çÄv
const"
var_859_end_mask_0


*'
name

"
op_859_end_mask_0* 
val


	

¬
slice_by_index
begin

var_859_begin_0
x


logits"
end_mask

var_859_end_mask_0
end

var_859_end_0%
var_859


¿
Ä*
name


"
op_859{
const$
prefix_tokens_perm_0


**
name"

"
prefix_tokens_perm_0* 
val


	

 j
const
var_863


*
name


"
op_863**
val#




ˇˇˇˇˇˇˇˇˇ((ê
	transpose 
perm

prefix_tokens_perm_0
x
	
var_859+
prefix_tokens


Ä
¿*"
name

"
transpose_79Ü
reshape
x

prefix_tokens
shape
	
var_863,
	input_161


Ä
(
(*
name

"
	input_161¥
linear
x
	
var_853$
bias

model_mask_head_fc1_bias(
weight

model_mask_head_fc1_weight'
	input_153


»
Ä*
name

"
	linear_73e
const
input_155_mode_0
*&
name

"
input_155_mode_0*
val

	"
EXACTÇ
gelu
x

	input_153
mode

input_155_mode_0'
	input_155


»
Ä*
name

"
	input_155∂
linear
x

	input_155$
bias

model_mask_head_fc2_bias(
weight

model_mask_head_fc2_weight'
	input_157


»
Ä*
name

"
	linear_74e
const
input_159_mode_0
*&
name

"
input_159_mode_0*
val

	"
EXACTÇ
gelu
x

	input_157
mode

input_159_mode_0'
	input_159


»
Ä*
name

"
	input_159¥
linear
x

	input_159$
bias

model_mask_head_fc3_bias(
weight

model_mask_head_fc3_weight%
var_878


»
Ä*
name

"
	linear_75m
const
input_163_pad_type_0
**
name"

"
input_163_pad_type_0*
val

	"
validx
const#
input_163_strides_0


*)
name!

"
input_163_strides_0*
val




r
const
input_163_pad_0


*%
name

"
input_163_pad_0*!
val





    |
const%
input_163_dilations_0


*+
name#

"
input_163_dilations_0*
val




e
const
input_163_groups_0
*(
name 

"
input_163_groups_0*
val


ß
const9
)input_163_has_output_shape_output_shape_0


*?
name7
/
-"+
)input_163_has_output_shape_output_shape_0*"
val



	
ÄPP
conv_transpose&
	dilations

input_163_dilations_06
weight,
*
(model_upscale_block_block_0_conv1_weight=
output_shape-
+
)input_163_has_output_shape_output_shape_0
pad

input_163_pad_0 
groups

input_163_groups_0
x

	input_161"
strides

input_163_strides_0$
pad_type

input_163_pad_type_02
bias*
(
&model_upscale_block_block_0_conv1_bias=
input_163_has_output_shape


Ä
P
P*0
name(
 
"
input_163_has_output_shapee
const
input_165_mode_0
*&
name

"
input_165_mode_0*
val

	"
EXACTò
gelu#
x

input_163_has_output_shape
mode

input_165_mode_0,
	input_165


Ä
P
P*
name

"
	input_165z
const"
hidden_state_49_pad_type_0
*0
name(
 
"
hidden_state_49_pad_type_0*
val


"
custom~
const%
hidden_state_49_pad_0


*+
name#

"
hidden_state_49_pad_0*!
val





r
const 
hidden_state_49_groups_0
*.
name&

"
hidden_state_49_groups_0*
val


ÄÑ
const)
hidden_state_49_strides_0


*/
name'

"
hidden_state_49_strides_0*
val




à
const+
hidden_state_49_dilations_0


*1
name)
!
"
hidden_state_49_dilations_0*
val




˚
conv
x

	input_165&
groups

hidden_state_49_groups_0 
pad

hidden_state_49_pad_06
weight,
*
(model_upscale_block_block_0_conv2_weight,
	dilations

hidden_state_49_dilations_0(
strides

hidden_state_49_strides_0*
pad_type

hidden_state_49_pad_type_02
hidden_state_49


Ä
P
P*%
name

"
hidden_state_49a
const
var_902


*
name


"
op_902*!
val





 Ü
const&
hidden_state_51_axes_0


*,
name$

"
hidden_state_51_axes_0*'
val 





ˇˇˇˇˇˇˇˇˇå
	transpose
perm
	
var_902
x

hidden_state_49,
	input_167


P
P
Ä*"
name

"
transpose_78≠

layer_norm
epsilon


var_108
beta0
.
,model_upscale_block_block_0_layernorm2d_bias
x

	input_167;
gamma2
0
.model_upscale_block_block_0_layernorm2d_weight"
axes

hidden_state_51_axes_02
hidden_state_51


P
P
Ä*%
name

"
hidden_state_51a
const
var_906


*
name


"
op_906*!
val





 m
const
input_171_pad_type_0
**
name"

"
input_171_pad_type_0*
val

	"
validx
const#
input_171_strides_0


*)
name!

"
input_171_strides_0*
val




r
const
input_171_pad_0


*%
name

"
input_171_pad_0*!
val





    |
const%
input_171_dilations_0


*+
name#

"
input_171_dilations_0*
val




e
const
input_171_groups_0
*(
name 

"
input_171_groups_0*
val


©
const9
)input_171_has_output_shape_output_shape_0


*?
name7
/
-"+
)input_171_has_output_shape_output_shape_0*$
val



	
Ä††å
	transpose
perm
	
var_906
x

hidden_state_51,
	input_169


Ä
P
P*"
name

"
transpose_77Ú
conv_transpose&
	dilations

input_171_dilations_06
weight,
*
(model_upscale_block_block_1_conv1_weight=
output_shape-
+
)input_171_has_output_shape_output_shape_0
pad

input_171_pad_0 
groups

input_171_groups_0
x

	input_169"
strides

input_171_strides_0$
pad_type

input_171_pad_type_02
bias*
(
&model_upscale_block_block_1_conv1_bias?
input_171_has_output_shape!


Ä
†
†*0
name(
 
"
input_171_has_output_shapee
const
input_173_mode_0
*&
name

"
input_173_mode_0*
val

	"
EXACTö
gelu#
x

input_171_has_output_shape
mode

input_173_mode_0.
	input_173!


Ä
†
†*
name

"
	input_173z
const"
hidden_state_53_pad_type_0
*0
name(
 
"
hidden_state_53_pad_type_0*
val


"
custom~
const%
hidden_state_53_pad_0


*+
name#

"
hidden_state_53_pad_0*!
val





r
const 
hidden_state_53_groups_0
*.
name&

"
hidden_state_53_groups_0*
val


ÄÑ
const)
hidden_state_53_strides_0


*/
name'

"
hidden_state_53_strides_0*
val




à
const+
hidden_state_53_dilations_0


*1
name)
!
"
hidden_state_53_dilations_0*
val




˝
conv
x

	input_173&
groups

hidden_state_53_groups_0 
pad

hidden_state_53_pad_06
weight,
*
(model_upscale_block_block_1_conv2_weight,
	dilations

hidden_state_53_dilations_0(
strides

hidden_state_53_strides_0*
pad_type

hidden_state_53_pad_type_04
hidden_state_53!


Ä
†
†*%
name

"
hidden_state_53a
const
var_927


*
name


"
op_927*!
val





 Ä
const#
hidden_state_axes_0


*)
name!

"
hidden_state_axes_0*'
val 





ˇˇˇˇˇˇˇˇˇä
	transpose
perm
	
var_927
x

hidden_state_53*
input!


†
†
Ä*"
name

"
transpose_76¢

layer_norm
epsilon


var_108
beta0
.
,model_upscale_block_block_1_layernorm2d_bias
x	

input;
gamma2
0
.model_upscale_block_block_1_layernorm2d_weight
axes

hidden_state_axes_01
hidden_state!


†
†
Ä*"
name

"
hidden_statea
const
var_931


*
name


"
op_931*!
val





 f
const
concat_9


*
name

"

concat_9*#
val





ÄÄ»â
	transpose
perm
	
var_931
x

hidden_state,
var_932!


Ä
†
†*"
name

"
transpose_75}
reshape
x
	
var_932
shape


concat_9(
	reshape_1


Ä
Ä»*
name

"
	reshape_1o
const
matmul_12_transpose_x_0
*-
name%

"
matmul_12_transpose_x_0*
val


 o
const
matmul_12_transpose_y_0
*-
name%

"
matmul_12_transpose_y_0*
val


 —
matmul*
transpose_y

matmul_12_transpose_y_0
x
	
var_878
y

	reshape_1*
transpose_x

matmul_12_transpose_x_0(
	matmul_12


»
Ä»*
name

"
	matmul_12i
const
	concat_13


*
name

"
	concat_13*$
val



	
»††Ü
reshape
x

	matmul_12
shape

	concat_13.
	reshape_2!


»
†
†*
name

"
	reshape_2o
const
var_934_perm_0


*#
name

"
op_934_perm_0*!
val





 ë
	transpose
perm

var_934_perm_0
x

	reshape_20
mask_logits!


»
†
†*"
name

"
transpose_74"Á
	buildInfoŸ"


∆"√
8
!

"
coremltools-version

	"
8.3.0
@
)
!
"
coremltools-component-torch

	"
2.8.0
E
(
 
"
coremltools-source-dialect

"
TorchScript
import matplotlib.pyplot as plt
import torch
from PIL import Image
import numpy as np
import coremltools as ct
from transformers import AutoImageProcessor, AutoConfig

# ---------------------------------------------------------------------------
# 1. ì„¤ì • & ë¡œë“œ
# ---------------------------------------------------------------------------
mlmodel_path = "EOMT_2.mlpackage" 
model_id = "tue-mps/coco_panoptic_eomt_small_640_2x"

# í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ ì¸ë±ìŠ¤ ì„¤ì •
image_names= ["000000015497", "000000104572", "000000130699", "000000131273", "000000161861", "000000261116", "000000356424", "000000377393", "000000389315", "000000391648"]
idx = 9
image_path = f'evaluation/val_images_random10/images/{image_names[idx]}.jpg'
#image_path = f'evaluation/val_images_random10/images/Marketplace.jpg'
print(f"ğŸ“¥ Loading Processor & Config...")
processor = AutoImageProcessor.from_pretrained(model_id)
config = AutoConfig.from_pretrained(model_id)
id2label = config.id2label 

print(f"ğŸš€ Loading Core ML model...")
model = ct.models.MLModel(mlmodel_path)

# ---------------------------------------------------------------------------
# 2. ì…ë ¥ ë°ì´í„° ì¤€ë¹„ (Letterbox Resize)
# ---------------------------------------------------------------------------
image = Image.open(image_path).convert("RGB")

def resize_with_padding(image, target_size=(640, 640)):
    target_w, target_h = target_size
    orig_w, orig_h = image.size
    
    # ë¹„ìœ¨ ìœ ì§€ ë¦¬ì‚¬ì´ì¦ˆ ë¹„ìœ¨ ê³„ì‚°
    ratio = min(target_w / orig_w, target_h / orig_h)
    new_w = int(orig_w * ratio)
    new_h = int(orig_h * ratio)
    
    resized_image = image.resize((new_w, new_h), resample=Image.BICUBIC)
    
    # ê²€ì€ ë°°ê²½ ìƒì„±
    new_image = Image.new("RGB", target_size, (0, 0, 0))
    paste_x = (target_w - new_w) // 2
    paste_y = (target_h - new_h) // 2
    new_image.paste(resized_image, (paste_x, paste_y))
    
    return new_image, (paste_x, paste_y, new_w, new_h)

# ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ ë° íŒ¨ë”© ì •ë³´ ì €ì¥
input_image, pad_info = resize_with_padding(image, target_size=(640, 640))
paste_x, paste_y, new_w, new_h = pad_info  # ë‚˜ì¤‘ì— ìë¥¼ ë•Œ ì‚¬ìš©

# ---------------------------------------------------------------------------
# 3. ì¶”ë¡  (Core ML)
# ---------------------------------------------------------------------------
print("ğŸ”® Running Core ML Prediction...")
preds = model.predict({"pixel_values": input_image})

# ---------------------------------------------------------------------------
# 4. í›„ì²˜ë¦¬ (Post-processing) - ë°ì´í„° íƒ€ì… ìˆ˜ì •ë¨
# ---------------------------------------------------------------------------
class CoreMLOutputWrapper:
    def __init__(self, class_logits, mask_logits):
        self.class_queries_logits = torch.from_numpy(class_logits)
        self.masks_queries_logits = torch.from_numpy(mask_logits)

c_logits = preds["class_logits"]
m_logits = preds["mask_logits"]

if c_logits.ndim == 2: c_logits = np.expand_dims(c_logits, 0)
if m_logits.ndim == 3: m_logits = np.expand_dims(m_logits, 0)

outputs = CoreMLOutputWrapper(c_logits, m_logits)

print("âš™ï¸ Post-processing...")

# [1ë‹¨ê³„] ì¼ë‹¨ íŒ¨ë”©ì´ í¬í•¨ëœ 640x640 í¬ê¸°ë¡œ ê²°ê³¼ë¥¼ ë°›ìŠµë‹ˆë‹¤.
final_preds = processor.post_process_panoptic_segmentation(
    outputs,
    target_sizes=[(640, 640)], 
    threshold=0.8
)

# 640x640 ê²°ê³¼ ì¶”ì¶œ
seg_640 = final_preds[0]["segmentation"].cpu().numpy()
segments_info = final_preds[0]["segments_info"]

# [2ë‹¨ê³„] íŒ¨ë”© ì œê±° (Crop)
seg_cropped = seg_640[paste_y : paste_y + new_h, paste_x : paste_x + new_w]

# [3ë‹¨ê³„] ì›ë³¸ í¬ê¸°ë¡œ ë³µì› (Resize)
# âš ï¸ [ìˆ˜ì •ëœ ë¶€ë¶„] int64 -> int32 ë³€í™˜ ì¶”ê°€ (PIL í˜¸í™˜ì„± ë¬¸ì œ í•´ê²°)
seg_cropped = seg_cropped.astype(np.int32) 

seg_pil = Image.fromarray(seg_cropped)
seg_resized = seg_pil.resize(image.size, resample=Image.NEAREST)
seg_final = np.array(seg_resized)

# ---------------------------------------------------------------------------
# [ìˆ˜ì •] ì‹œê°í™” (ì˜¤ë²„ë ˆì´ + ë¼ë²¨ í…ìŠ¤íŠ¸) - ê³ ì • ìƒ‰ìƒ ë¡œì§ ì ìš©
# ---------------------------------------------------------------------------
print(f"Found {len(segments_info)} segments.")
H, W = seg_final.shape 

# ë¹ˆ ë„í™”ì§€ ìƒì„±
color_img = np.zeros((H, W, 3), dtype=np.uint8)

# âœ¨ [í•µì‹¬ ë³€ê²½] ID ê¸°ë°˜ ìƒ‰ìƒ ìƒì„± í•¨ìˆ˜
def get_stable_color(id_value):
    # ID ê°’ì„ ì‹œë“œë¡œ ì‚¬ìš©í•˜ì—¬ í•­ìƒ ë˜‘ê°™ì€ ëœë¤ ìƒ‰ì„ ë§Œë“¦
    rng_stable = np.random.default_rng(id_value)
    return rng_stable.integers(0, 255, size=3, dtype=np.uint8)

for s in segments_info:
    segment_id = s["id"]
    label_id = s["label_id"]
    
    # ë°©ë²• A: ì„¸ê·¸ë¨¼íŠ¸ ID ê¸°ì¤€ (ê°™ì€ ê°ì²´ëŠ” í•­ìƒ ê°™ì€ ìƒ‰) - ì¶”ì²œ
    color = get_stable_color(segment_id)
    
    # ë°©ë²• B: í´ë˜ìŠ¤ ê¸°ì¤€ (ëª¨ë“  'ì‚¬ëŒ'ì€ ê°™ì€ ìƒ‰) - ì›í•˜ë©´ ì´ê±¸ë¡œ êµì²´
    # color = get_stable_color(label_id)

    # ìƒ‰ì¹ í•˜ê¸°
    color_img[seg_final == segment_id] = color

# (ì´í•˜ ì˜¤ë²„ë ˆì´ ë° í…ìŠ¤íŠ¸ ì½”ë“œëŠ” ë™ì¼)
overlay = Image.blend(image.convert("RGBA"), Image.fromarray(color_img).convert("RGBA"), alpha=0.6)
# 2) í”Œë¡¯ ê·¸ë¦¬ê¸°
plt.figure(figsize=(12, 12))
plt.imshow(overlay)
plt.axis("off")

# 3) ë¼ë²¨ í…ìŠ¤íŠ¸ ì°ê¸° ë£¨í”„
print("ğŸ· Adding labels...")
for s in segments_info:
    segment_id = s["id"]
    label_id = s["label_id"]
    score = s.get("score", None)
    
    # ì›ë³¸ í¬ê¸° ë§ˆìŠ¤í¬ ê¸°ì¤€ìœ¼ë¡œ ì¢Œí‘œ ì°¾ê¸°
    mask = (seg_final == segment_id)
    ys, xs = np.where(mask) 
    
    if len(ys) == 0:
        continue
        
    # ë¬´ê²Œ ì¤‘ì‹¬(Center of Mass) ê³„ì‚°
    cy, cx = np.mean(ys), np.mean(xs)
    
    # ë¼ë²¨ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
    label_name = id2label.get(label_id, str(label_id))
    
    # í…ìŠ¤íŠ¸ êµ¬ì„±
    txt = f"{label_name}"
    if score is not None:
        txt += f"\n{score:.2f}"
    
    # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
    plt.text(
        cx, cy, txt, 
        color="white", 
        fontsize=9, 
        fontweight='bold',
        ha="center", va="center",
        bbox=dict(facecolor="black", alpha=0.6, edgecolor='none', boxstyle='round,pad=0.3')
    )

plt.title(f"Core ML Panoptic Segmentation ({len(segments_info)} objects)")
plt.tight_layout()
plt.show()